# ğŸŒŒ Tradyxa RubiX

> **Probabilistic Edge Intelligence for NIFTY & BANKNIFTY Options Traders**
> 
> *Zero-Cost Architecture â€¢ Institutional-Grade Algorithms â€¢ Real-Time Probability Surfaces*

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.12-blue.svg)
![Vite+React](https://img.shields.io/badge/vite+react-5.4-purple.svg)
![Status](https://img.shields.io/badge/status-production-green.svg)
![Data](https://img.shields.io/badge/data-yfinance-orange.svg)

---

## ğŸ¯ Project Vision

**Tradyxa RubiX** is a **probabilistic edge intelligence dashboard** built specifically for **NIFTY and BANKNIFTY options traders**. Unlike generic stock screeners or basic charting tools, Tradyxa RubiX focuses on **quantifying uncertainty**, **probability modeling**, and **risk-adjusted decision making** using formulas and methodologies employed by **Goldman Sachs, BlackRock, DE Shaw, and Citadel**.

### Why "Tradyxa RubiX"?

- **Omega (Î©)**: Represents the ultimate completion, the final answer to trading uncertainty
- **Vault**: Your protected repository of institutional-grade intelligence

---

## â“ Frequently Asked Questions (Deep Dive)

### Q1: How is Omega Vault different from AlephX, BetaX, GammaX, DeltaX?

| Project | Focus | Tiles | Unique Feature |
|---------|-------|-------|----------------|
| **AlephX** | General NIFTY options dashboard | 12 | Basic volatility + ML predictions, Next.js |
| **BetaX (Aegis Matrix)** | Direction/Seller/Buyer engines | 22 | BiLSTM deep learning for direction, 3 specialized engines |
| **GammaX (Aztryx)** | 500 stocks analysis | 12 | Slippage prediction, investment sizing for Nifty 500 |
| **DeltaX (AuztinX)** | Basic ML tiles | 12 | Kalman filter, GARCH volatility, K-Means levels |
| **OmegaX (This Project)** | **Probability-first edge intelligence** | 16 | **Kelly Criterion, VaR, HMM Regime, Monte Carlo, Barrier Breach** |

**What makes Omega STANDALONE and UNIQUE:**

1. **Probability Focus**: Other projects show "BUY/SELL" signals. Omega shows **probabilities** (e.g., "67% chance of uptrend")
2. **Risk Management**: Only Omega has **Kelly Criterion position sizing** and **VaR risk gauges**
3. **Institutional Formulas**: Uses **Goldman Sachs-style barrier probability**, **BlackRock-style CVaR**, **DE Shaw-style HMM**
4. **Trader Psychology**: Designed to answer "Should I trade?" AND "How much should I risk?"
5. **No Overlap**: Completely different tile set, formulas, and use cases

---

### Q2: We train on 20 years of data, then fetch today's spot price. But is the conclusion for TODAY, TOMORROW, or NEXT WEEK?

**HONEST ANSWER:** The predictions have **MULTIPLE time horizons**:

| Tile | Prediction Horizon | Best For |
|------|-------------------|----------|
| **Regime Beacon** | Current state (RIGHT NOW) | Knowing if today is a good day to trade |
| **Momentum Pulse** | Next 1-3 days | Intraday & swing traders |
| **Streak Reversal** | Next 1 day (tomorrow) | Overnight position holders |
| **Range Quartiles** | Next 1 day | Setting stop-loss and targets |
| **Friday Fear** | Weekend (2-3 days) | Weekly expiry traders |
| **Monte Carlo Cones** | Next 1-5 days | Swing traders |
| **Kelly Optimal** | Current trade | Position sizing for any timeframe |
| **VaR Gauge** | Next 1 day | Risk for overnight positions |

**CONCLUSION:**
- **Intraday traders**: Use Regime Beacon + Momentum Pulse + Current VIX
- **Swing traders (1-5 days)**: Use Monte Carlo Cones + Range Quartiles + Streak Reversal
- **Weekly expiry traders**: Use Friday Fear + Theta Decay + Barrier Breach
- **Monthly expiry traders**: Use Regime Beacon + Kelly Optimal (for sizing)

---

### Q3: How is this helpful for INTRADAY traders vs SWING traders?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHO BENEFITS FROM WHAT?                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  INTRADAY TRADER (Same day, exit by 3:30 PM)                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                             â”‚
â”‚  âœ… USE: Regime Beacon â†’ "Is market TRENDING or CHOPPY right now?"       â”‚
â”‚  âœ… USE: Momentum Pulse â†’ "Is there momentum to ride?"                   â”‚
â”‚  âœ… USE: VIX Current â†’ "Is volatility high enough for scalping?"         â”‚
â”‚  âœ… USE: Range Quartiles â†’ "What's today's expected range?"              â”‚
â”‚  âŒ SKIP: Friday Fear, Monte Carlo 5-day cones                           â”‚
â”‚                                                                          â”‚
â”‚  SWING TRADER (1-5 days, overnight positions)                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                             â”‚
â”‚  âœ… USE: Monte Carlo Cones â†’ "Where will price be in 3-5 days?"          â”‚
â”‚  âœ… USE: Streak Reversal â†’ "Will trend continue or reverse?"             â”‚
â”‚  âœ… USE: Regime Beacon â†’ "Should I hold overnight?"                      â”‚
â”‚  âœ… USE: Kelly Optimal â†’ "How much to risk on this swing?"               â”‚
â”‚  âœ… USE: VaR Gauge â†’ "What's my worst-case overnight loss?"              â”‚
â”‚                                                                          â”‚
â”‚  WEEKLY EXPIRY TRADER (Hold till Thursday/Friday)                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                          â”‚
â”‚  âœ… USE: Friday Fear â†’ "Is gap risk high this weekend?"                  â”‚
â”‚  âœ… USE: Theta Decay â†’ "When does time decay accelerate?"                â”‚
â”‚  âœ… USE: Barrier Breach â†’ "Will my strike be touched?"                   â”‚
â”‚  âœ… USE: VIX Term Structure â†’ "Is it good to sell premium?"              â”‚
â”‚                                                                          â”‚
â”‚  MONTHLY EXPIRY TRADER (Hold 2-4 weeks)                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                 â”‚
â”‚  âœ… USE: Regime Beacon â†’ "What's the dominant regime this month?"        â”‚
â”‚  âœ… USE: Kelly Optimal â†’ "Max position size for this month?"             â”‚
â”‚  âœ… USE: Range Quartiles (extended) â†’ "Monthly expected range"           â”‚
â”‚  âš ï¸ Note: Predictions beyond 5 days have lower accuracy                  â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Q4: Do the ML models detect HIDDEN PATTERNS in NIFTY/BANKNIFTY/VIX?

**YES, but let's be HONEST about what "hidden patterns" means:**

```mermaid
graph TB
    subgraph WHAT_ML_FINDS["ğŸ” What ML Models Actually Find"]
        P1["Pattern 1: STREAK EXHAUSTION<br/>After 4+ consecutive up days,<br/>reversal probability = 65%"]
        P2["Pattern 2: VIX REGIME SHIFT<br/>When VIX drops below 12 AND<br/>stays there 3+ days = TRENDING"]
        P3["Pattern 3: VOLATILITY COMPRESSION<br/>When 10d vol < 20d vol < 60d vol,<br/>breakout probability increases"]
        P4["Pattern 4: RSI + STREAK COMBO<br/>RSI > 70 AND streak > 3 days,<br/>mean reversion likely"]
        P5["Pattern 5: FRIDAY ANOMALY<br/>Fridays before monthly expiry<br/>have 23% higher volatility"]
    end
    
    subgraph WHAT_ML_CANNOT_FIND["âŒ What ML Cannot Find"]
        N1["News events (RBI announcements)"]
        N2["Global market shocks (US Fed)"]
        N3["Black swan events"]
        N4["Insider trading patterns"]
        N5["Sentiment from social media"]
    end
    
    subgraph HOW_IT_HELPS["âœ… How Hidden Patterns Help"]
        H1["Confirms your intuition with DATA"]
        H2["Catches patterns human eyes miss"]
        H3["Removes emotional bias"]
        H4["Provides probability, not certainty"]
    end
    
    WHAT_ML_FINDS --> HOW_IT_HELPS
    WHAT_ML_CANNOT_FIND -.->|"These are NOT detected"| HOW_IT_HELPS
    
    style WHAT_ML_FINDS fill:#10b981,color:#fff
    style WHAT_ML_CANNOT_FIND fill:#ef4444,color:#fff
    style HOW_IT_HELPS fill:#3b82f6,color:#fff
```

**The ML models find patterns like:**
- "When RSI is above 70 AND VIX is below 13 AND there's been a 3-day streak, historically the market reversed 62% of the time"
- "When volatility compresses for 5 days AND volume drops, breakout happens within 2 days 71% of the time"

**These are STATISTICAL patterns, not crystal ball predictions.**

---

### Q5: If I fetch spot price and mix with ML conclusion, does that analysis hold VALUE? How can traders TRUST it?

**VERY IMPORTANT QUESTION. Here's the HONEST answer:**

**Why the analysis HOLDS VALUE:**

| Reason | Explanation |
|--------|-------------|
| **1. Historical Validation** | Models are trained on 20 years = 5,000+ trading days. Patterns that worked 60%+ of the time are captured. |
| **2. Not Random Guessing** | A coin flip is 50%. If the model is 60% accurate, you have a +10% edge over random. |
| **3. Consistent Logic** | Unlike human emotions, the model applies the SAME logic every time. No fear, no greed. |
| **4. Multi-Factor Analysis** | Model considers 60+ features simultaneously. Humans can track maybe 5-6 at once. |
| **5. Probability, Not Certainty** | Model says "67% bullish" not "definitely bullish". You decide if 67% is good enough. |

**Why you should NOT blindly trust it:**

| Risk | Reality Check |
|------|---------------|
| **1. Past â‰  Future** | Patterns from 2010 may not work in 2024. Market evolves. |
| **2. No News Awareness** | Model doesn't know RBI will announce rate cut tomorrow. |
| **3. Black Swans** | COVID crash, demonetization - no model predicted these. |
| **4. Overfitting Risk** | Model might have "learned" noise instead of signal. |
| **5. Regime Breaks** | When market fundamentally changes, old patterns break. |

**THE RIGHT WAY TO USE IT:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  HOW TO USE OMEGA VAULT CORRECTLY                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  âœ… DO: Use as CONFIRMATION of your own analysis                     â”‚
â”‚     "I think market will go up, does Omega agree?"                   â”‚
â”‚                                                                      â”‚
â”‚  âœ… DO: Use for POSITION SIZING                                      â”‚
â”‚     "Omega says Kelly = 15%, so I'll risk only 15% of capital"       â”‚
â”‚                                                                      â”‚
â”‚  âœ… DO: Use for RISK MANAGEMENT                                      â”‚
â”‚     "VaR says 2.5% max loss, so my stop-loss is at 2.5%"            â”‚
â”‚                                                                      â”‚
â”‚  âœ… DO: Check REGIME before trading                                  â”‚
â”‚     "Omega shows CHAOTIC regime, I'll skip trading today"           â”‚
â”‚                                                                      â”‚
â”‚  âŒ DON'T: Follow blindly without your own analysis                  â”‚
â”‚     "Omega says 65% bullish, I'll go all-in blind"                   â”‚
â”‚                                                                      â”‚
â”‚  âŒ DON'T: Ignore news and fundamentals                              â”‚
â”‚     "Budget day tomorrow but Omega doesn't know, so ignore"          â”‚
â”‚                                                                      â”‚
â”‚  âŒ DON'T: Expect 100% accuracy                                      â”‚
â”‚     "Omega was wrong once, it's useless"                             â”‚
â”‚                                                                      â”‚
â”‚  âŒ DON'T: Use for naked options selling without risk management     â”‚
â”‚     "Omega says low VIX, I'll sell naked strangles"                  â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Q6: How ACCURATE will the predictions be? Will it be SNIPER ACCURATE?

**BRUTALLY HONEST ANSWER: NO, it will NOT be sniper accurate.**

**Here's the reality of ML prediction accuracy:**

| Accuracy Level | What It Means | Is It Realistic? |
|----------------|---------------|------------------|
| **95-100%** | "Sniper accurate" | âŒ **IMPOSSIBLE** - If anyone had this, they'd be trillionaires |
| **80-90%** | "Very good" | âŒ **Unrealistic** - Even top hedge funds rarely achieve this |
| **70-80%** | "Good edge" | âš ï¸ **Rare** - Top quant funds achieve this on specific strategies |
| **60-70%** | "Solid edge" | âœ… **Realistic** - This is what Omega Vault aims for |
| **55-60%** | "Slight edge" | âœ… **Common** - Still profitable with proper risk management |
| **50%** | "Coin flip" | âŒ **No value** - Random guessing |

**What Omega Vault's models REALISTICALLY achieve:**

| Model | Backtested Accuracy | Live Accuracy (Expected) |
|-------|--------------------|-----------------------------|
| **HMM Regime** | 65-70% | 60-65% |
| **RF Reversal** | 62-68% | 58-62% |
| **XGB Momentum** | 60-65% | 55-60% |
| **QR Range** | Â±15% error | Â±20% error |
| **GBM Divergence** | 58-63% | 55-58% |

**Why 60% accuracy is STILL VALUABLE:**

```
  MATH OF EDGE:
  
  100 trades with 60% accuracy
  â”œâ”€â”€ 60 winning trades Ã— â‚¹100 profit = â‚¹6,000
  â””â”€â”€ 40 losing trades Ã— â‚¹100 loss = â‚¹4,000
      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      NET PROFIT = â‚¹2,000 (20% return!)
  
  With Kelly sizing at 1:1 risk-reward:
  - 60% win rate = Kelly suggests 20% of capital per trade
  - Fractional Kelly (1/4) = 5% per trade
  - This compounds to significant returns over time
```

**Why it CAN'T be sniper accurate:**

1. **Markets are RANDOM + PATTERN**: About 60% noise, 40% pattern. No one can predict the noise.
2. **Information Asymmetry**: Institutional traders have news faster than you.
3. **Self-Fulfilling Prophecy**: If a pattern becomes too known, it stops working.
4. **Black Swans**: Unpredictable events destroy any model.
5. **Regime Changes**: Markets evolve; 2020 patterns â‰  2024 patterns.

**THE HONEST EXPECTATION:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              WHAT TO EXPECT FROM OMEGA VAULT                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  âœ… EXPECT: 55-65% directional accuracy on most tiles                â”‚
â”‚  âœ… EXPECT: Better risk management decisions                         â”‚
â”‚  âœ… EXPECT: Objective, emotion-free analysis                         â”‚
â”‚  âœ… EXPECT: Historical context for your decisions                    â”‚
â”‚  âœ… EXPECT: Probability-based thinking instead of gut feeling        â”‚
â”‚                                                                      â”‚
â”‚  âŒ DON'T EXPECT: 90%+ accuracy ("sniper accurate")                  â”‚
â”‚  âŒ DON'T EXPECT: Perfect prediction of news events                  â”‚
â”‚  âŒ DON'T EXPECT: Get-rich-quick signals                             â”‚
â”‚  âŒ DON'T EXPECT: Replacement for learning trading                   â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Q7: Is mixing LIVE SPOT PRICE with ML CONCLUSION the correct approach?

**YES, this is EXACTLY how institutional traders do it.** Here's why:

```mermaid
graph TB
    subgraph TRAINING["ğŸ“š TRAINING (Weekly)"]
        T1["20 Years Historical Data"]
        T2["Learn: 'When RSI > 70 AND streak > 3,<br/>reversal happened 65% of the time'"]
        T3["Save this PATTERN in the brain (.pkl)"]
    end
    
    subgraph INFERENCE["âš¡ INFERENCE (Every 30 min)"]
        I1["Fetch TODAY's spot price"]
        I2["Calculate TODAY's RSI, streak, etc."]
        I3["Ask brain: 'Given today's RSI = 72,<br/>streak = 4, what's the probability?'"]
        I4["Brain says: 'Based on 5000 similar days,<br/>reversal probability = 68%'"]
    end
    
    subgraph VALUE["ğŸ’ THE VALUE"]
        V1["You get: HISTORICAL CONTEXT<br/>for TODAY's decision"]
        V2["Brain remembers 2008, 2020, 2022 crashes<br/>and what patterns preceded them"]
        V3["You make INFORMED decision,<br/>not GUESSING"]
    end
    
    TRAINING --> INFERENCE
    INFERENCE --> VALUE
    
    style TRAINING fill:#f59e0b,color:#000
    style INFERENCE fill:#3b82f6,color:#fff
    style VALUE fill:#10b981,color:#fff
```

**Why this approach WORKS:**

| Principle | Explanation |
|-----------|-------------|
| **Pattern Recognition** | ML finds patterns in 5000+ days that humans can't see |
| **Context Transfer** | Today's RSI=72 + streak=4 has happened 200 times before. What happened next? |
| **Probability Estimation** | Out of 200 similar situations, 130 reversed = 65% reversal probability |
| **Fresh Data** | Live spot price ensures you're applying patterns to CURRENT state |

**The loop is CORRECT:**

```
HISTORICAL DATA          LIVE DATA              PREDICTION
(20 years OHLCV)    +    (Today's spot)    =    (Probability)
     â†“                        â†“                      â†“
   BRAIN              Feed to BRAIN             OUTPUT
   (.pkl)             for inference             (JSON)
```

---

### Q8: How will this help a trader who wants to know "How will NIFTY be for coming days?"

**DIRECT ANSWER:** The dashboard helps you understand PROBABILITY, not CERTAINTY.

| What You Ask | What Omega Tells You |
|--------------|---------------------|
| "Will NIFTY go up tomorrow?" | "Based on current regime + indicators, probability of up move is 62%" |
| "What's the expected range?" | "Q50 (median) range is Â±180 points, Q90 (extreme) is Â±320 points" |
| "Should I hold my position?" | "Regime is TRENDING with 71% confidence, streak reversal probability is 35% (low)" |
| "How much should I risk?" | "Kelly Optimal says 12% of capital, VaR 95% shows max loss 1.8%" |
| "Is this a good time to trade?" | "Regime is CHAOTIC (avoid) or TRENDING (proceed)" |

**For coming days (1-5 days):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TILE                    â”‚  WHAT IT TELLS YOU FOR COMING DAYS       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Regime Beacon           â”‚  Will current trend CONTINUE or CHANGE?  â”‚
â”‚  Monte Carlo Cones       â”‚  Price distribution for next 1-5 days    â”‚
â”‚  Range Quartiles         â”‚  Expected min/max range for tomorrow     â”‚
â”‚  Momentum Pulse          â”‚  Strength of move for next 1-3 days      â”‚
â”‚  Streak Reversal         â”‚  Will current streak reverse tomorrow?   â”‚
â”‚  Friday Fear             â”‚  Weekend gap risk for F&O positions      â”‚
â”‚  Barrier Breach          â”‚  Probability of touching key strikes     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Q9: Summary - Is Omega Vault worth using?

| If You Are... | Omega Vault... |
|---------------|----------------|
| **Beginner trader** | Helps you think in PROBABILITIES instead of certainties |
| **Emotional trader** | Gives you OBJECTIVE, data-driven signals |
| **Option seller** | Shows VIX regime, risk levels, and premium decay timing |
| **Option buyer** | Shows momentum, breakout probability, and barrier levels |
| **Risk-averse trader** | Kelly + VaR tells you exactly how much to risk |
| **News-driven trader** | âŒ Won't help - model doesn't know news |
| **Looking for 100% accuracy** | âŒ Wrong tool - no tool gives 100% |

**FINAL VERDICT:**

> **Omega Vault is a DECISION SUPPORT TOOL, not a DECISION MAKER.**
> 
> It gives you probabilities, risk metrics, and historical context.
> YOU make the final decision based on your own analysis + Omega's insights.
> 
> **Think of it as a CO-PILOT, not an AUTOPILOT.**

---

## ğŸ“Š Tile Data Source Matrix (What Uses What)

### Quick Reference: Which Tiles Use ML Models?

| # | Tile Name | Type | Engine | Purpose |
|---|-----------|------|--------|---------|
| **1** | **Spot Price** | **Live** | **Market Data** | **Real-time NIFTY/BANKNIFTY Price** |
| **2** | **India VIX** | **Live** | **Market Data** | **Real-time Volatility Index** |
| 3 | Probability Surface | Model | Monte Carlo | 3D visual of where price can go |
| 4 | Regime Beacon | ML | HMM | Current market state (Trending/Choppy) |
| 5 | Kelly Optimal | Formula | Kelly Criterion | Exact position sizing % |
| 6 | VaR Gauge | Formula | Value at Risk | Worst-case loss estimation |
| 7 | Hurst Compass | Formula | Fractal Analysis | Trend strength (0-1) |
| 8 | VIX Term Contour | Formula | Term Structure | Volatility future expectations |
| 9 | Friday Fear | Formula | Gap Statistics | Weekend hold risk |
| 10 | Theta Decay | Formula | Black-Scholes | Time decay acceleration visual |
| 11 | Monte Carlo Cones | Model | Simulation | 5-day forecasted price cones |
| 12 | Barrier Breach | Formula | Probability | Chance of touching a level |
| 13 | Streak Reversal | ML | Random Forest | Probability of trend reversal |
| 14 | Pain Zone | Formula | Volume Weights | Max pain for option sellers |
| 15 | Range Quartiles | ML | Quantile Reg | Expected High/Low range |
| 16 | Momentum Pulse | ML | XGBoost | Trend force and direction |
| 17 | GEX Cluster | Formula | Volume Proxy | Gamma Exposure estimation |
| 18 | Event Radar | Static | Calendar | Upcoming big events |
| **19** | **Trade Traffic Light** | **Logic** | **Confluence** | **Simple Red/Yellow/Green Signal** |
| **20** | **FOMO Meter** | **Logic** | **RSI + Bollinger** | **Prevents chasing tops/bottoms** |

**Summary**: 4 tiles use ML, 16 tiles use statistical/logic formulas

---

### Complete Data Source Matrix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TILE NAME            â”‚ ML? â”‚ NIFTY â”‚ BANK  â”‚ VIX â”‚ FORMULA/MODEL                                          â”‚
â”‚                       â”‚     â”‚ SPOT  â”‚ NIFTY â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Spot Price        â”‚ âŒ  â”‚  âœ…   â”‚  âœ…   â”‚ âŒ  â”‚ Direct Feed â†’ Real-time Display                         â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. India VIX         â”‚ âŒ  â”‚  âŒ   â”‚  âŒ   â”‚ âœ…  â”‚ Direct Feed â†’ Real-time Display                         â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. Probability       â”‚ âŒ  â”‚  âœ…   â”‚  âŒ   â”‚ âœ…  â”‚ NIFTY Spot + VIX â†’ Monte Carlo 10,000 paths             â”‚
â”‚     Surface           â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  4. Regime Beacon     â”‚ âœ…  â”‚  âœ…   â”‚  âŒ   â”‚ âœ…  â”‚ NIFTY Returns + VIX â†’ HMM Trained Model â†’ Regime       â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  5. Kelly Optimal     â”‚ âŒ  â”‚  âœ…   â”‚  âŒ   â”‚ âŒ  â”‚ NIFTY Historical Win Rate â†’ Kelly Formula              â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  6. VaR Gauge         â”‚ âŒ  â”‚  âœ…   â”‚  âŒ   â”‚ âŒ  â”‚ NIFTY Returns â†’ Historical VaR + CVaR                  â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  7. Hurst Compass     â”‚ âŒ  â”‚  âœ…   â”‚  âŒ   â”‚ âŒ  â”‚ NIFTY Close â†’ R/S Analysis â†’ Hurst Exponent            â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  8. VIX Term Contour  â”‚ âŒ  â”‚  âŒ   â”‚  âŒ   â”‚ âœ…  â”‚ VIX 5d avg vs 20d avg â†’ Term Structure                 â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  9. Friday Fear       â”‚ âŒ  â”‚  âœ…   â”‚  âŒ   â”‚ âŒ  â”‚ NIFTY Friday Close â†’ Monday Open â†’ Gap Statistics      â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  10. Theta Decay      â”‚ âŒ  â”‚  âœ…   â”‚  âŒ   â”‚ âœ…  â”‚ NIFTY Spot + VIX (as IV) â†’ Black-Scholes Theta         â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  11. Monte Carlo Conesâ”‚ âŒ  â”‚  âœ…   â”‚  âŒ   â”‚ âœ…  â”‚ NIFTY Spot + VIX â†’ 10,000 Simulated Paths              â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  12. Barrier Breach   â”‚ âŒ  â”‚  âœ…   â”‚  âŒ   â”‚ âœ…  â”‚ NIFTY Spot + VIX â†’ Black-Scholes Barrier Prob          â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  13. Streak Reversal  â”‚ âœ…  â”‚  âœ…   â”‚  âŒ   â”‚ âœ…  â”‚ NIFTY Spot + Features + VIX â†’ RF Trained Model         â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  14. Pain Zone        â”‚ âŒ  â”‚  âœ…   â”‚  âŒ   â”‚ âŒ  â”‚ NIFTY Close + Volume â†’ Volume-Weighted Average         â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  15. Range Quartiles  â”‚ âœ…  â”‚  âœ…   â”‚  âŒ   â”‚ âœ…  â”‚ NIFTY Spot + Features + VIX â†’ QR Trained Model         â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  16. Momentum Pulse   â”‚ âœ…  â”‚  âœ…   â”‚  âŒ   â”‚ âœ…  â”‚ NIFTY Spot + Features + VIX â†’ XGB + GBM Models         â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  17. GEX Cluster      â”‚ âŒ  â”‚  âœ…   â”‚  âŒ   â”‚ âŒ  â”‚ NIFTY Volume â†’ Volume Change Proxy                     â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  18. Event Radar      â”‚ âŒ  â”‚  âœ…   â”‚  âŒ   â”‚ âŒ  â”‚ Calendar Events + NIFTY Historical Impact              â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  19. Trade Traffic    â”‚ âœ…  â”‚  âœ…   â”‚  âŒ   â”‚ âœ…  â”‚ Confluence Logic (Regime + VIX + Momentum)             â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  20. FOMO Meter       â”‚ âŒ  â”‚  âœ…   â”‚  âŒ   â”‚ âŒ  â”‚ RSI + Bollinger Band Logic                             â”‚
â”‚                       â”‚     â”‚       â”‚       â”‚     â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Detailed Data Flow Per Tile

#### ğŸ”´ **ML-POWERED TILES (4 Tiles)**

```mermaid
graph TB
    subgraph TILE2["Tile 2: Regime Beacon ğŸš¦"]
        T2_IN["ğŸ“¥ INPUTS"]
        T2_NIFTY["NIFTY Spot (Live)"]
        T2_NIFTY_HIST["NIFTY OHLCV (1 Year)"]
        T2_VIX["India VIX"]
        T2_MODEL["ğŸ§  HMM Regime Model"]
        T2_OUT["ğŸ“¤ OUTPUT: TRENDING / REVERTING / CHAOTIC"]
        
        T2_NIFTY --> T2_IN
        T2_NIFTY_HIST --> T2_IN
        T2_VIX --> T2_IN
        T2_IN --> |"Build Features:<br/>return_1d, volatility_20d"| T2_MODEL
        T2_MODEL --> T2_OUT
    end
    
    style TILE2 fill:#10b981,color:#fff
```

```mermaid
graph TB
    subgraph TILE11["Tile 11: Streak Reversal ğŸ”„"]
        T11_IN["ğŸ“¥ INPUTS"]
        T11_NIFTY["NIFTY Spot (Live)"]
        T11_HIST["NIFTY OHLCV (1 Year)"]
        T11_VIX["India VIX"]
        T11_FEAT["Features: streak, RSI, BB,<br/>MACD, volatility, volume"]
        T11_MODEL["ğŸ§  Random Forest Model"]
        T11_OUT["ğŸ“¤ OUTPUT: Reversal Probability 0-100%"]
        
        T11_NIFTY --> T11_IN
        T11_HIST --> T11_IN
        T11_VIX --> T11_IN
        T11_IN --> T11_FEAT
        T11_FEAT --> T11_MODEL
        T11_MODEL --> T11_OUT
    end
    
    style TILE11 fill:#3b82f6,color:#fff
```

```mermaid
graph TB
    subgraph TILE13["Tile 13: Range Quartiles ğŸ“Š"]
        T13_IN["ğŸ“¥ INPUTS"]
        T13_NIFTY["NIFTY Spot (Live)"]
        T13_HIST["NIFTY OHLCV (1 Year)"]
        T13_VIX["India VIX"]
        T13_FEAT["Features: ATR, volatility,<br/>VIX, volume_ratio, RSI"]
        T13_MODEL["ğŸ§  Quantile Regression Model"]
        T13_OUT["ğŸ“¤ OUTPUT: Q10, Q25, Q50, Q75, Q90<br/>Price Ranges"]
        
        T13_NIFTY --> T13_IN
        T13_HIST --> T13_IN
        T13_VIX --> T13_IN
        T13_IN --> T13_FEAT
        T13_FEAT --> T13_MODEL
        T13_MODEL --> T13_OUT
    end
    
    style TILE13 fill:#f59e0b,color:#000
```

```mermaid
graph TB
    subgraph TILE14["Tile 14: Momentum Pulse ğŸ’“"]
        T14_IN["ğŸ“¥ INPUTS"]
        T14_NIFTY["NIFTY Spot (Live)"]
        T14_HIST["NIFTY OHLCV (1 Year)"]
        T14_VIX["India VIX"]
        T14_FEAT["Features: RSI, MACD, returns,<br/>volatility, VIX percentile"]
        T14_MODEL1["ğŸ§  XGBoost Momentum"]
        T14_MODEL2["ğŸ§  GBM Divergence"]
        T14_OUT["ğŸ“¤ OUTPUT: Momentum Score 0-100<br/>+ Divergence Detection"]
        
        T14_NIFTY --> T14_IN
        T14_HIST --> T14_IN
        T14_VIX --> T14_IN
        T14_IN --> T14_FEAT
        T14_FEAT --> T14_MODEL1
        T14_FEAT --> T14_MODEL2
        T14_MODEL1 --> T14_OUT
        T14_MODEL2 --> T14_OUT
    end
    
    style TILE14 fill:#8b5cf6,color:#fff
```

---

#### ğŸ”µ **STATISTICAL/FORMULA TILES (16 Tiles)**

| Tile | Exact Input Combination | Formula/Method | Output |
|------|------------------------|----------------|--------|
| **1. Spot Price** | Direct Feed | `yfinance.fast_info` | Real-time Price |
| **2. India VIX** | Direct Feed | `yfinance.fast_info` | Real-time Volatility |
| **3. Probability Surface** | NIFTY Spot + VIX (as Ïƒ) | `merton_jump_diffusion(spot, vix/100, T=5)` | 3D probability heatmap |
| **5. Kelly Optimal** | NIFTY Historical Returns | `(p*b - q) / b` where p=win_rate, q=1-p, b=avg_win/avg_loss | Position size % |
| **6. VaR Gauge** | NIFTY 1-year Returns | `np.percentile(returns, [5, 1])` | 95%, 99% VaR |
| **7. Hurst Compass** | NIFTY Close Prices | `rescaled_range_analysis(close, 200)` | Hurst Exponent 0-1 |
| **8. VIX Term Contour** | VIX only | `(vix_20d_avg - vix_5d_avg) / vix_20d_avg` | Contango/Backwardation |
| **9. Friday Fear** | NIFTY Fri Close, Mon Open | `np.percentile(abs(gaps), [50,75,90])` | Gap percentiles |
| **10. Theta Decay** | NIFTY Spot + VIX | `black_scholes_theta(S, K, T, r, sigma)` | Decay curve |
| **11. Monte Carlo Cones**| NIFTY Spot + VIX | `np.percentile(simulated_paths, [16,50,84])` | 1Ïƒ, 2Ïƒ, 3Ïƒ cones |
| **12. Barrier Breach** | NIFTY Spot + VIX + Strike | `prob_touch_barrier(spot, barrier, sigma, T)` | Touch probability |
| **14. Pain Zone** | NIFTY Close + Volume | `np.average(prices, weights=volumes)` | Volume-weighted center |
| **17. GEX Cluster** | NIFTY Volume | `volume_change * 0.1` (proxy only) | Estimated GEX |
| **18. Event Radar** | Calendar + NIFTY History | Lookup table of event impacts | Upcoming events |
| **19. Trade Traffic** | Regime + VIX + Momentum | `IF Trending AND VIX<20 AND Mom>60 THEN GREEN` | GO/WAIT/STOP Signal |
| **20. FOMO Meter** | RSI + Bollinger | `Mean Reversion Logic` | Overbought/Oversold Gauge |

---

### Data Source Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA SOURCES BY TILE                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  NIFTY SPOT PRICE (Live, every 30 min)                                      â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                       â”‚
â”‚  Used by: ALL 16 TILES                                                      â”‚
â”‚  Source: yfinance.Ticker("^NSEI").fast_info                                â”‚
â”‚                                                                             â”‚
â”‚  NIFTY OHLCV HISTORY (1 Year, cached)                                       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                        â”‚
â”‚  Used by: ALL 16 TILES                                                      â”‚
â”‚  Source: yfinance.download("^NSEI", period="1y")                           â”‚
â”‚  Purpose: Calculate RSI, MACD, Bollinger, Returns, Volatility              â”‚
â”‚                                                                             â”‚
â”‚  INDIA VIX (Live + Historical)                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                              â”‚
â”‚  Used by: 10 TILES (1, 2, 6, 8, 9, 10, 11, 13, 14, and implied vol tiles)  â”‚
â”‚  Source: yfinance.download("^INDIAVIX")                                    â”‚
â”‚  Purpose: Volatility input for Black-Scholes, VIX percentile, term struct â”‚
â”‚                                                                             â”‚
â”‚  BANKNIFTY DATA                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                            â”‚
â”‚  Used by: OPTIONAL (if user selects BANKNIFTY view)                        â”‚
â”‚  Note: Dashboard defaults to NIFTY, can switch to BANKNIFTY                â”‚
â”‚  All formulas apply same way to BANKNIFTY                                  â”‚
â”‚                                                                             â”‚
â”‚  ML TRAINED MODELS (.pkl files)                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                             â”‚
â”‚  Used by: 4 TILES (2, 11, 13, 14)                                          â”‚
â”‚  Source: Weekly training on 20 years of NIFTY + VIX data                   â”‚
â”‚  Stored: models/hmm_regime.pkl, rf_reversal.pkl, qr_range.pkl, etc.       â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Visual: ML Tiles vs Non-ML Tiles

```
                    20 TILES IN OMEGA VAULT
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                        â”‚
    â”‚   ğŸ§  ML-POWERED (4 tiles)     â”‚   ğŸ“Š STATISTICAL (16)  â”‚
    â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•       â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
    â”‚                               â”‚                        â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚   â”‚ 4. Regime Beacon â”‚        â”‚   â”‚ 1. Spot Price    â”‚ â”‚
    â”‚   â”‚    (HMM)         â”‚        â”‚   â”‚ 2. India VIX     â”‚ â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚ 3. Prob Surface  â”‚ â”‚
    â”‚                               â”‚   â”‚ 5. Kelly Optimal â”‚ â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚ 6. VaR Gauge     â”‚ â”‚
    â”‚   â”‚ 13. Streak       â”‚        â”‚   â”‚ 7. Hurst Compass â”‚ â”‚
    â”‚   â”‚     Reversal     â”‚        â”‚   â”‚ 8. VIX Term      â”‚ â”‚
    â”‚   â”‚     (RF)         â”‚        â”‚   â”‚ 9. Friday Fear   â”‚ â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚ 10. Theta Decay  â”‚ â”‚
    â”‚                               â”‚   â”‚ 11. MC Cones     â”‚ â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚ 12. Barrier      â”‚ â”‚
    â”‚   â”‚ 15. Range        â”‚        â”‚   â”‚ 14. Pain Zone    â”‚ â”‚
    â”‚   â”‚     Quartiles    â”‚        â”‚   â”‚ 17. GEX Cluster  â”‚ â”‚
    â”‚   â”‚     (QR)         â”‚        â”‚   â”‚ 18. Event Radar  â”‚ â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚ 19. Traffic Lightâ”‚ â”‚
    â”‚                               â”‚   â”‚ 20. FOMO Meter   â”‚ â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚   â”‚ 16. Momentum     â”‚        â”‚                        â”‚
    â”‚   â”‚     Pulse        â”‚        â”‚                        â”‚
    â”‚   â”‚     (XGB+GBM)    â”‚        â”‚                        â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚                        â”‚
    â”‚                               â”‚                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ML tiles use: NIFTY Spot + NIFTY History + VIX + Trained Brain (.pkl)
    Statistical tiles use: NIFTY Spot + NIFTY History + VIX (formulas only)
```

---

## ğŸ“Š The Problem We Solve

| Problem | Competition | Omega Vault Solution |
|---------|-------------|---------------------|
| Traders rely on **gut feeling** | Basic candlestick charts | **Bayesian probability signals** with confidence intervals |
| No understanding of **expected value** | "Buy/Sell" alerts | **Kelly Criterion position sizing** with bankroll optimization |
| Ignoring **regime changes** | Static indicators | **Hidden Markov Model regime detection** updated every 30 min |
| Fear of **VIX spikes** | Simple VIX number | **VIX Term Structure analysis** with contango/backwardation signals |
| Options **theta decay** blindness | Premium calculators | **Optimal DTE heatmaps** with decay acceleration curves |
| **Weekend gap risk** ignorance | No gap analysis | **Friday Close Risk Index** with historical gap distributions |

---

## ğŸ† Zero Competition Moat

### What Makes This Unique?

1. **Probability-First Design**: Every tile shows probabilities, not just signals
2. **Options-Specific Intelligence**: Designed for F&O traders, not equity investors
3. **Institutional Formulas Made Accessible**: Complex math â†’ simple visual tiles
4. **NIFTY/BANKNIFTY Focus**: Not diluted across 500 stocks
5. **Free Forever**: Ad-supported, no premium paywalls
6. **SEBI Compliant**: No recommendations, only statistical analysis

### Target Audience

- **Option Buyers**: Looking for high-probability breakout entries
- **Option Sellers**: Seeking low-volatility premium collection windows
- **Straddle/Strangle Traders**: Needing volatility regime clarity
- **Weekly Expiry Traders**: Requiring gamma/theta decay timing
- **Position Sizing Beginners**: Learning bankroll management

---

## ğŸ§  Core Intelligence Engines

### 1. **The Probability Oracle** (Primary Engine)
Generates probability distributions for next-day price movements using:
- **Bayesian Updating**: Prior beliefs + new OHLCV evidence
- **Monte Carlo Simulations**: 10,000 path simulations per run
- **Jump-Diffusion Models** (Merton): Accounts for sudden gaps

### 2. **The Regime Sentinel** (Market State Engine)
Detects and classifies market regimes:
- **Hidden Markov Models (HMM)**: 3-state regime (Trending/Mean-Reverting/Chaotic)
- **Markov Switching GARCH**: Volatility regime transitions
- **Structural Break Detection**: Identifies regime shift events

### 3. **The Risk Architect** (Position Sizing Engine)
Optimizes trade sizing using:
- **Kelly Criterion**: Optimal fraction of bankroll per trade
- **Fractional Kelly (1/4 Kelly)**: Conservative risk management
- **Value at Risk (VaR)**: 95% and 99% confidence loss bounds
---

## ğŸ—ï¸ System Architecture (Mermaid Diagrams)

### 1. High-Level System Architecture

```mermaid
graph TB
    subgraph USER["ğŸ‘¤ USER"]
        BROWSER["ğŸŒ Browser<br/>Desktop / Mobile"]
    end
    
    subgraph FRONTEND["âš›ï¸ FRONTEND (Vite + React)"]
        REACT["React 18<br/>TypeScript"]
        TILES["16 Tile Components"]
        CHARTS["Recharts<br/>Visualizations"]
        THEME["TRON Legacy<br/>Theme"]
    end
    
    subgraph CDN["â˜ï¸ CLOUDFLARE PAGES"]
        STATIC["Static Files<br/>HTML/CSS/JS"]
        JSON_DATA["omega_vault.json<br/>Predictions Data"]
    end
    
    subgraph GITHUB["ğŸ”§ GITHUB"]
        REPO["Repository<br/>Source Code"]
        ACTIONS["GitHub Actions<br/>CI/CD"]
        MODELS["models/*.pkl<br/>THE BRAIN"]
    end
    
    subgraph PYTHON["ğŸ PYTHON ENGINE"]
        TRAIN["train_all_models.py<br/>Weekly Training"]
        INFER["infer.py<br/>Daily Inference"]
        FEATURES["feature_builder.py<br/>60+ Features"]
    end
    
    subgraph YFINANCE["ğŸ“Š YFINANCE API"]
        NIFTY["^NSEI<br/>NIFTY 50"]
        BANK["^NSEBANK<br/>BANKNIFTY"]
        VIX["^INDIAVIX<br/>India VIX"]
    end
    
    USER --> BROWSER
    BROWSER --> CDN
    CDN --> STATIC
    CDN --> JSON_DATA
    
    ACTIONS --> TRAIN
    ACTIONS --> INFER
    TRAIN --> MODELS
    MODELS --> INFER
    
    YFINANCE --> TRAIN
    YFINANCE --> INFER
    INFER --> JSON_DATA
    
    REPO --> ACTIONS
    
    REACT --> TILES
    TILES --> CHARTS
    CHARTS --> THEME
    
    style USER fill:#4c1d95,color:#fff
    style FRONTEND fill:#3b82f6,color:#fff
    style CDN fill:#f59e0b,color:#000
    style GITHUB fill:#1f2937,color:#fff
    style PYTHON fill:#10b981,color:#fff
    style YFINANCE fill:#ef4444,color:#fff
```

---

### 2. Complete Data Pipeline Flow

```mermaid
flowchart TB
    subgraph SOURCES["ğŸ“Š DATA SOURCES"]
        YF["yfinance API"]
        NIFTY_D["NIFTY OHLCV<br/>2005 â†’ Present"]
        BANK_D["BANKNIFTY OHLCV<br/>2005 â†’ Present"]
        VIX_D["India VIX<br/>2008 â†’ Present"]
    end
    
    subgraph STORAGE["ğŸ’¾ DATA STORAGE"]
        CSV["Local CSV Cache<br/>data/*.csv"]
        PKL["Model Files<br/>models/*.pkl"]
    end
    
    subgraph PROCESSING["ğŸ”§ PROCESSING"]
        FETCH["data_fetcher.py<br/>Download Data"]
        CLEAN["Data Cleaning<br/>Handle Missing Values"]
        ENGINEER["feature_builder.py<br/>60+ Technical Features"]
    end
    
    subgraph TRAINING["ğŸ§  MODEL TRAINING"]
        HMM["HMM Regime<br/>hmmlearn"]
        RF["Random Forest<br/>sklearn"]
        XGB["XGBoost<br/>Gradient Boosting"]
        QR["Quantile Regression<br/>sklearn"]
        GBM["GBM Divergence<br/>sklearn"]
    end
    
    subgraph INFERENCE["âš¡ INFERENCE"]
        LOAD["Load .pkl Models"]
        LIVE["Fetch Live Prices"]
        MIX["Mix Features + Brain"]
        PREDICT["Generate Predictions"]
    end
    
    subgraph OUTPUT["ğŸ“¤ OUTPUT"]
        JSON["omega_vault.json"]
        DASH["Dashboard<br/>16 Tiles"]
    end
    
    YF --> NIFTY_D & BANK_D & VIX_D
    NIFTY_D & BANK_D & VIX_D --> FETCH
    FETCH --> CSV
    CSV --> CLEAN
    CLEAN --> ENGINEER
    
    ENGINEER --> HMM & RF & XGB & QR & GBM
    HMM & RF & XGB & QR & GBM --> PKL
    
    PKL --> LOAD
    YF --> LIVE
    LOAD & LIVE --> MIX
    MIX --> PREDICT
    PREDICT --> JSON
    JSON --> DASH
    
    style SOURCES fill:#ef4444,color:#fff
    style PROCESSING fill:#f59e0b,color:#000
    style TRAINING fill:#10b981,color:#fff
    style INFERENCE fill:#3b82f6,color:#fff
    style OUTPUT fill:#8b5cf6,color:#fff
```

---

### 3. GitHub Actions CI/CD Workflow

```mermaid
flowchart LR
    subgraph TRIGGERS["ğŸ¯ TRIGGERS"]
        CRON_SAT["â° Cron<br/>Saturday 00:00 UTC"]
        CRON_30["â° Cron<br/>Every 30 min M-F"]
        MANUAL["ğŸ–±ï¸ Manual<br/>workflow_dispatch"]
    end
    
    subgraph WEEKLY["ğŸ“… WEEKLY TRAINING"]
        W1["Checkout Repo"]
        W2["Setup Python 3.12"]
        W3["Install Dependencies"]
        W4["Run train_all_models.py"]
        W5["Commit models/*.pkl"]
        W6["Push to main"]
    end
    
    subgraph DAILY["âš¡ DAILY INFERENCE"]
        D1["Checkout Repo"]
        D2["Setup Python 3.12"]
        D3["Install Dependencies"]
        D4["Run infer.py"]
        D5["Commit omega_vault.json"]
        D6["Push to main"]
    end
    
    subgraph DEPLOY["ğŸš€ DEPLOY"]
        CF["Cloudflare Pages<br/>Auto-deploy on push"]
        LIVE["Live Dashboard<br/>Updated"]
    end
    
    CRON_SAT --> W1
    MANUAL --> W1
    W1 --> W2 --> W3 --> W4 --> W5 --> W6
    
    CRON_30 --> D1
    D1 --> D2 --> D3 --> D4 --> D5 --> D6
    
    W6 --> CF
    D6 --> CF
    CF --> LIVE
    
    style TRIGGERS fill:#f59e0b,color:#000
    style WEEKLY fill:#10b981,color:#fff
    style DAILY fill:#3b82f6,color:#fff
    style DEPLOY fill:#8b5cf6,color:#fff
```

---

### 4. Frontend-Backend Interaction

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant B as ğŸŒ Browser
    participant CF as â˜ï¸ Cloudflare
    participant GH as ğŸ”§ GitHub Actions
    participant PY as ğŸ Python Engine
    participant YF as ğŸ“Š yfinance
    
    Note over GH,YF: Every 30 min during market hours
    
    GH->>PY: Run infer.py
    PY->>YF: fetch("^NSEI", "^NSEBANK", "^INDIAVIX")
    YF-->>PY: OHLCV + Live Prices
    PY->>PY: Build features (60+)
    PY->>PY: Load models/*.pkl (THE BRAIN)
    PY->>PY: Run predictions
    PY->>GH: Generate omega_vault.json
    GH->>CF: git push (triggers deploy)
    CF->>CF: Rebuild & Deploy
    
    Note over U,B: User opens dashboard
    
    U->>B: Open omega-vault.com
    B->>CF: GET /
    CF-->>B: index.html + JS bundle
    B->>CF: GET /data/omega_vault.json
    CF-->>B: Predictions JSON
    B->>B: Render 16 tiles
    B-->>U: Display dashboard
    
    Note over B: Auto-refresh every 5 min
    
    B->>CF: GET /data/omega_vault.json
    CF-->>B: Updated predictions
    B->>B: Re-render tiles
    B-->>U: Updated display
```

---

### 5. Model Training Deep Dive

```mermaid
flowchart TB
    subgraph INPUT["ğŸ“¥ INPUT DATA"]
        RAW["20 Years OHLCV<br/>~5,000 Trading Days"]
    end
    
    subgraph FEATURES["ğŸ”§ FEATURE ENGINEERING"]
        direction TB
        F1["Price Features<br/>Returns, Log Returns"]
        F2["Volatility Features<br/>10d, 20d, 60d Rolling"]
        F3["Technical Indicators<br/>RSI, MACD, BB, ATR"]
        F4["VIX Features<br/>Level, Percentile, Term"]
        F5["Volume Features<br/>Ratio, Change"]
        F6["Streak Features<br/>Consecutive Up/Down"]
    end
    
    subgraph LABELS["ğŸ·ï¸ LABEL GENERATION"]
        direction TB
        L1["Reversal Label<br/>Did streak reverse?"]
        L2["Momentum Label<br/>Was there 1.5%+ move?"]
        L3["Range Label<br/>What was next-day range?"]
        L4["Regime Label<br/>HMM assigns states"]
    end
    
    subgraph SPLIT["âœ‚ï¸ TRAIN/TEST SPLIT"]
        TRAIN_SET["Training Set<br/>80% (~4,000 days)"]
        TEST_SET["Test Set<br/>20% (~1,000 days)"]
    end
    
    subgraph ALGORITHMS["ğŸ§  ML ALGORITHMS"]
        direction TB
        ALG1["HMM<br/>Expectation-Maximization"]
        ALG2["Random Forest<br/>200 Trees, Gini Split"]
        ALG3["XGBoost<br/>Gradient Boosting"]
        ALG4["Quantile Regression<br/>Q10, Q25, Q50, Q75, Q90"]
        ALG5["Gradient Boosting<br/>100 Trees"]
    end
    
    subgraph OPTIMIZATION["âš™ï¸ OPTIMIZATION"]
        OPT1["Minimize Error<br/>Cross-Entropy Loss"]
        OPT2["Find Best Splits<br/>Gini Impurity"]
        OPT3["Iteratively Reduce<br/>Residual Errors"]
    end
    
    subgraph OUTPUT["ğŸ’¾ OUTPUT"]
        PKL1["hmm_regime.pkl"]
        PKL2["rf_reversal.pkl"]
        PKL3["xgb_momentum.pkl"]
        PKL4["qr_range.pkl"]
        PKL5["gbm_divergence.pkl"]
    end
    
    RAW --> FEATURES
    F1 & F2 & F3 & F4 & F5 & F6 --> LABELS
    LABELS --> SPLIT
    SPLIT --> TRAIN_SET & TEST_SET
    TRAIN_SET --> ALGORITHMS
    ALGORITHMS --> OPTIMIZATION
    OPTIMIZATION --> OUTPUT
    
    style INPUT fill:#ef4444,color:#fff
    style FEATURES fill:#f59e0b,color:#000
    style LABELS fill:#84cc16,color:#000
    style ALGORITHMS fill:#10b981,color:#fff
    style OUTPUT fill:#3b82f6,color:#fff
```

---

### 6. Dashboard Rendering Flow

```mermaid
flowchart TB
    subgraph FETCH["ğŸ“¡ DATA FETCHING"]
        REACT_QUERY["React Query<br/>useQuery()"]
        JSON_FETCH["Fetch omega_vault.json"]
        CACHE["5-min Cache<br/>Stale-while-revalidate"]
    end
    
    subgraph PARSE["ğŸ” DATA PARSING"]
        VALIDATE["Zod Schema<br/>Validation"]
        TRANSFORM["Transform to<br/>Tile Props"]
    end
    
    subgraph TILES["ğŸ¨ TILE RENDERING"]
        direction LR
        T1["Tile 1<br/>Probability"]
        T2["Tile 2<br/>Regime"]
        T3["Tile 3<br/>Kelly"]
        T4["Tile 4<br/>VaR"]
        T5["..."]
        T16["Tile 16<br/>Events"]
    end
    
    subgraph CHARTS["ğŸ“Š CHART COMPONENTS"]
        RECHARTS["Recharts Library"]
        LINE["Line Charts"]
        BAR["Bar Charts"]
        GAUGE["Gauge Dials"]
        HEATMAP["Heatmaps"]
    end
    
    subgraph STYLING["ğŸ¨ STYLING"]
        TAILWIND["Tailwind CSS"]
        FRAMER["Framer Motion<br/>Animations"]
        TRON["TRON Theme<br/>Cyan Glow"]
    end
    
    subgraph DISPLAY["ğŸ–¥ï¸ DISPLAY"]
        GRID["4x4 Grid Layout"]
        HERO["Verdict Hero Section"]
        RESPONSIVE["Responsive<br/>Mobile/Desktop"]
    end
    
    REACT_QUERY --> JSON_FETCH
    JSON_FETCH --> CACHE
    CACHE --> VALIDATE
    VALIDATE --> TRANSFORM
    TRANSFORM --> TILES
    
    T1 & T2 & T3 & T4 & T5 & T16 --> CHARTS
    CHARTS --> RECHARTS
    RECHARTS --> LINE & BAR & GAUGE & HEATMAP
    
    TILES --> STYLING
    TAILWIND & FRAMER & TRON --> DISPLAY
    GRID & HERO --> RESPONSIVE
    
    style FETCH fill:#3b82f6,color:#fff
    style PARSE fill:#f59e0b,color:#000
    style TILES fill:#10b981,color:#fff
    style CHARTS fill:#8b5cf6,color:#fff
    style DISPLAY fill:#ec4899,color:#fff
```

---

### 7. Complete End-to-End Flow

```mermaid
graph TB
    subgraph WEEK["ğŸ“… WEEKLY (Saturday)"]
        W1["ğŸŒ yfinance<br/>Download 20 Years"]
        W2["ğŸ”§ Build 60+ Features"]
        W3["ğŸ§  Train 5 Models"]
        W4["ğŸ’¾ Save .pkl Files"]
        W5["ğŸ“¤ Commit to GitHub"]
    end
    
    subgraph DAY["âš¡ EVERY 30 MIN (M-F)"]
        D1["ğŸŒ yfinance<br/>Fetch Live Prices"]
        D2["ğŸ“‚ Load .pkl Models"]
        D3["ğŸ”§ Build Today's Features"]
        D4["ğŸ”„ Mix Features + Brain"]
        D5["ğŸ“Š Generate Predictions"]
        D6["ğŸ“¤ Save omega_vault.json"]
        D7["ğŸš€ Deploy to Cloudflare"]
    end
    
    subgraph USER["ğŸ‘¤ USER REQUEST"]
        U1["ğŸŒ Open Browser"]
        U2["ğŸ“¡ Fetch JSON"]
        U3["ğŸ¨ Render 16 Tiles"]
        U4["âœ¨ Display Dashboard"]
    end
    
    W1 --> W2 --> W3 --> W4 --> W5
    W5 -.->|"Models ready"| D2
    
    D1 --> D3
    D2 --> D4
    D3 --> D4
    D4 --> D5 --> D6 --> D7
    
    D7 -.->|"Data ready"| U2
    U1 --> U2 --> U3 --> U4
    
    style WEEK fill:#f59e0b,color:#000
    style DAY fill:#10b981,color:#fff
    style USER fill:#3b82f6,color:#fff
```

---

### 8. Technology Stack Diagram

```mermaid
graph LR
    subgraph FRONTEND["âš›ï¸ Frontend Stack"]
        VITE["Vite 5.4"]
        REACT["React 18"]
        TS["TypeScript 5.3"]
        TW["Tailwind CSS 3.4"]
        FM["Framer Motion 11"]
        RC["Recharts 2.15"]
        RQ["React Query 5"]
    end
    
    subgraph BACKEND["ğŸ Backend Stack"]
        PY["Python 3.12"]
        YF["yfinance 0.2"]
        PD["Pandas 2.2"]
        NP["NumPy 1.26"]
        SK["scikit-learn 1.4"]
        XG["XGBoost 2.0"]
        HMM["hmmlearn 0.3"]
        JB["Joblib 1.4"]
    end
    
    subgraph INFRA["â˜ï¸ Infrastructure"]
        GH["GitHub<br/>Repository"]
        GA["GitHub Actions<br/>CI/CD"]
        CF["Cloudflare Pages<br/>Hosting"]
    end
    
    VITE --> REACT
    REACT --> TS
    TS --> TW
    TW --> FM
    FM --> RC
    RC --> RQ
    
    PY --> YF
    YF --> PD
    PD --> NP
    NP --> SK
    SK --> XG
    XG --> HMM
    HMM --> JB
    
    GH --> GA
    GA --> CF
    
    style FRONTEND fill:#3b82f6,color:#fff
    style BACKEND fill:#10b981,color:#fff
    style INFRA fill:#f59e0b,color:#000
```

---

### 9. Inference Decision Flow

```mermaid
flowchart TD
    START([Start Inference])
    
    FETCH["Fetch Live Data<br/>NIFTY, BANKNIFTY, VIX"]
    CHECK{"Data Available?"}
    
    FALLBACK["Use Cached Data<br/>Last Known Prices"]
    BUILD["Build Features<br/>60+ Indicators"]
    
    LOAD["Load Models<br/>5 .pkl Files"]
    CHECK_MODELS{"Models Exist?"}
    
    ERROR["Return Error<br/>Models Not Trained"]
    
    REGIME["HMM: Predict Regime<br/>TRENDING / REVERTING / CHAOTIC"]
    REVERSAL["RF: Predict Reversal<br/>Probability 0-100%"]
    MOMENTUM["XGB: Predict Momentum<br/>Score 0-100"]
    RANGE["QR: Predict Range<br/>Q10, Q25, Q50, Q75, Q90"]
    DIVERGENCE["GBM: Detect Divergence<br/>Bullish / Bearish"]
    
    COMBINE["Combine Predictions<br/>Build JSON Object"]
    VaR["Calculate VaR<br/>95%, 99% Bounds"]
    KELLY["Calculate Kelly<br/>Position Size"]
    
    SAVE["Save omega_vault.json"]
    DEPLOY["Trigger Cloudflare Deploy"]
    
    FINISH([End Inference])
    
    START --> FETCH
    FETCH --> CHECK
    CHECK -->|Yes| BUILD
    CHECK -->|No| FALLBACK
    FALLBACK --> BUILD
    
    BUILD --> LOAD
    LOAD --> CHECK_MODELS
    CHECK_MODELS -->|Yes| REGIME
    CHECK_MODELS -->|No| ERROR
    
    REGIME --> REVERSAL
    REVERSAL --> MOMENTUM
    MOMENTUM --> RANGE
    RANGE --> DIVERGENCE
    
    DIVERGENCE --> COMBINE
    COMBINE --> VaR
    VaR --> KELLY
    KELLY --> SAVE
    SAVE --> DEPLOY
    DEPLOY --> FINISH
    
    style START fill:#10b981,color:#fff
    style FINISH fill:#3b82f6,color:#fff
    style ERROR fill:#ef4444,color:#fff
```

---

### 10. User Journey Flow

```mermaid
journey
    title User Journey: From Landing to Trading Decision
    section Landing
      Open Website: 5: User
      See TRON Theme: 5: User
      View Verdict Hero: 5: User
    section Understanding
      Read Market Regime: 4: User
      Check Probability Surface: 4: User
      Review VaR Gauge: 4: User
    section Analysis
      Study Momentum Pulse: 3: User
      Check Streak Reversal: 3: User
      View Range Quartiles: 4: User
    section Decision
      Note Kelly Size: 5: User
      Set Position Size: 5: User
      Execute Trade: 5: User
    section Return
      Bookmark PWA: 5: User
      Return Every 30 min: 5: User
```

---

## ğŸ¤– Machine Learning Models - Complete Specification

### âœ… Your Understanding is 100% CORRECT!

Yes, this is EXACTLY what happens. Let me confirm with a clear diagram:

```mermaid
graph TB
    subgraph WEEKLY["ğŸ“… WEEKLY: Build The Brain (Saturdays)"]
        direction TB
        A1["ğŸ“¥ Download 20 Years Data<br/>NIFTY, BANKNIFTY, VIX<br/>from yfinance (2005 â†’ Now)"] 
        A2["ğŸ”§ Build 60+ Features<br/>RSI, MACD, Bollinger, VIX, etc."]
        A3["ğŸ§  Train 5 ML Models<br/>HMM, RandomForest, XGBoost, etc."]
        A4["ğŸ’¾ Save as .pkl files<br/>THE BRAIN<br/>(~9.4 MB)"]
        
        A1 --> A2 --> A3 --> A4
    end
    
    subgraph DAILY["âš¡ EVERY 30 MIN: Use The Brain (Market Hours)"]
        direction TB
        B1["ğŸ“¡ Fetch LIVE Prices<br/>NIFTY spot, BANKNIFTY spot, VIX<br/>from yfinance"]
        B2["ğŸ“‚ Load The Brain<br/>(pre-trained .pkl models)"]
        B3["ğŸ”„ Mix Live + Brain<br/>Build features from live data<br/>Feed to trained models"]
        B4["ğŸ“Š Generate Predictions<br/>Regime, Momentum, Range, etc."]
        B5["ğŸ–¥ï¸ Display on Dashboard<br/>16 Tiles Updated"]
        
        B1 --> B3
        B2 --> B3
        B3 --> B4 --> B5
    end
    
    A4 -.->|"Brain is ready<br/>waiting to be used"| B2
    
    style A4 fill:#f59e0b,color:#000
    style B3 fill:#10b981,color:#000
    style B5 fill:#3b82f6,color:#fff
```

### ğŸ”„ The Complete Flow (Simple Explanation)

| Step | When | What Happens | Result |
|------|------|--------------|--------|
| **1. Data Collection** | Weekly (Saturday) | Download 20 years of NIFTY, BANKNIFTY, VIX OHLCV data from yfinance | ~5,000 rows of historical data |
| **2. Feature Engineering** | Weekly (Saturday) | Calculate RSI, MACD, Bollinger Bands, volatility, VIX features, etc. | 60+ features per day |
| **3. Model Training** | Weekly (Saturday) | Feed features + labels to ML algorithms | 5 trained models (THE BRAIN) |
| **4. Save Brain** | Weekly (Saturday) | Save trained models as .pkl files | ~9.4 MB of "learned patterns" |
| **5. Load Brain** | Every 30 min (M-F) | Load the pre-trained .pkl models into memory | Brain is ready to predict |
| **6. Fetch Live Prices** | Every 30 min (M-F) | Get today's NIFTY spot, BANKNIFTY spot, VIX from yfinance | Current market state |
| **7. Mix Live + Brain** | Every 30 min (M-F) | Build features from live data, feed to brain | Predictions generated |
| **8. Display Dashboard** | Every 30 min (M-F) | Show predictions in 16 tiles | User sees insights |

---

## ğŸ“ How Training Actually Works (The Process Behind It)

### What is "Training" in Simple Terms?

**Training = Teaching the model patterns from historical data**

Imagine you want to teach a child to recognize when a market reversal is likely. You would show them thousands of examples:
- "When price went up 5 days in a row AND RSI was above 70, it reversed 65% of the time"
- "When VIX was below 12 AND volatility was low, market trended 70% of the time"

That's exactly what ML training does, but with math instead of words.

### The Training Process (Step-by-Step)

```mermaid
graph TB
    subgraph STEP1["STEP 1: Prepare Raw Data"]
        R1["20 Years OHLCV<br/>Open, High, Low, Close, Volume"]
        R2["~5,000 trading days<br/>for NIFTY, BANKNIFTY, VIX"]
    end
    
    subgraph STEP2["STEP 2: Create Features (X)"]
        F1["Calculate for EACH day:"]
        F2["â€¢ RSI = 65.3"]
        F3["â€¢ MACD = +12.5"]
        F4["â€¢ Volatility = 1.2%"]
        F5["â€¢ VIX = 14.2"]
        F6["â€¢ 60+ more features..."]
    end
    
    subgraph STEP3["STEP 3: Create Labels (Y)"]
        L1["For EACH day, what happened NEXT?"]
        L2["â€¢ Did price reverse? (0 or 1)"]
        L3["â€¢ Was there strong momentum? (0 or 1)"]
        L4["â€¢ What was the range? (number)"]
    end
    
    subgraph STEP4["STEP 4: Train the Model"]
        T1["Algorithm learns patterns:"]
        T2["IF RSI > 70 AND VIX < 15"]
        T3["THEN reversal probability = 0.65"]
        T4["These patterns stored in .pkl file"]
    end
    
    STEP1 --> STEP2
    STEP2 --> STEP3
    STEP3 --> STEP4
    
    style STEP2 fill:#3b82f6,color:#fff
    style STEP3 fill:#f59e0b,color:#000
    style STEP4 fill:#10b981,color:#fff
```

### Detailed Training Example: Streak Reversal Model

Let me show you EXACTLY how the Random Forest Reversal model learns:

#### Step 1: Create Feature-Label Pairs from Historical Data

```python
# For EACH day in 20 years of data, we create a row like this:

# Day: 2023-07-15
# FEATURES (X) - What we know BEFORE that day ended:
features = {
    'streak': 4,              # 4 consecutive up days
    'rsi_14': 72.3,           # RSI is overbought
    'bb_position': 0.92,       # Price near upper Bollinger
    'volatility_20d': 0.012,   # Low volatility
    'vix': 11.5,               # Low fear
    'volume_ratio': 1.3,       # Higher than usual volume
    # ... 10 total features
}

# LABEL (Y) - What ACTUALLY happened the next day:
label = 1  # The streak DID reverse (price went down on 2023-07-16)

# We do this for ALL 5,000 days!
```

#### Step 2: What the Training Algorithm Does

```python
# When we call model.fit(X, y), the Random Forest does this:

# 1. Creates 200 decision trees
# 2. Each tree looks at random subsets of data
# 3. Each tree learns patterns like:

#    TREE #1:
#    IF streak > 3 AND rsi_14 > 70:
#        IF vix < 12:
#            PREDICT: reversal = 75% likely
#        ELSE:
#            PREDICT: reversal = 55% likely
#    ELSE:
#        PREDICT: reversal = 35% likely

#    TREE #2 (different pattern):
#    IF bb_position > 0.9 AND volatility_20d < 0.015:
#        PREDICT: reversal = 68% likely
#    ...

# 3. All 200 trees vote together for final prediction
```

#### Step 3: How the Model "Learns" (The Math)

```python
# Training is an OPTIMIZATION process
# The model tries to MINIMIZE prediction errors

# For Random Forest:
# 1. Start with all 5,000 samples
# 2. Find the best "split" that separates reversals from non-reversals
#    Example: "IF streak > 3, split here"
# 3. Measure how well the split separates the data (Gini impurity)
# 4. Repeat recursively for each branch
# 5. Do this 200 times with random subsets â†’ 200 trees

# For XGBoost (Momentum model):
# 1. Start with a simple prediction (e.g., 50% momentum)
# 2. Calculate ERROR for each sample
# 3. Build a tree to PREDICT THE ERRORS
# 4. Add this tree to the model, reducing errors
# 5. Repeat 200 times â†’ each tree fixes previous errors

# For HMM (Regime model):
# 1. Assume there are 3 hidden states (regimes)
# 2. Use Expectation-Maximization (EM) algorithm
# 3. E-step: Estimate which regime each day belongs to
# 4. M-step: Update regime parameters (mean return, volatility)
# 5. Repeat until convergence
```

#### Step 4: What Gets Saved in the .pkl File (THE BRAIN)

```python
# After training, the .pkl file contains:

rf_reversal.pkl = {
    'model': RandomForestClassifier(
        # 200 decision trees with learned patterns
        n_estimators=200,
        
        # Each tree contains:
        # - Split rules: "IF streak > 3 THEN go left"
        # - Leaf values: "This leaf predicts 72% reversal"
        
        # Feature importances (what matters most):
        feature_importances_ = [
            ('streak', 0.23),        # Streak is most important
            ('rsi_14', 0.18),        # RSI is second
            ('bb_position', 0.15),   # Bollinger position third
            # ...
        ]
    ),
    'feature_cols': ['streak', 'rsi_14', 'bb_position', ...]
}

# This is "THE BRAIN" - learned patterns from 20 years of data
```

### Training vs Inference (Side by Side)

| Aspect | TRAINING (Weekly) | INFERENCE (Every 30 min) |
|--------|-------------------|--------------------------|
| **When** | Saturday 00:00 UTC | M-F 9:15 AM - 3:30 PM IST |
| **Data Used** | 20 years of history | Last 1 year + live prices |
| **What Happens** | Model LEARNS patterns | Model USES learned patterns |
| **Input** | 5,000 days of features + labels | 1 day of features (today) |
| **Output** | Trained .pkl files (brain) | Predictions (JSON) |
| **CPU/Memory** | High (10-15 min, 2GB RAM) | Low (30 sec, 300MB RAM) |
| **Changes Model?** | Yes (updates weights) | No (read-only) |

### Visual: How Live Prices Mix with The Brain

```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                    EVERY 30 MINUTES                         â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚                                                             â”‚
  â”‚  ğŸ“¡ FETCH LIVE PRICES                                       â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
  â”‚  â”‚ NIFTY Spot:     24,850.75              â”‚                â”‚
  â”‚  â”‚ BANKNIFTY Spot: 52,340.20              â”‚                â”‚
  â”‚  â”‚ India VIX:      12.35                   â”‚                â”‚
  â”‚  â”‚ (fetched via yfinance.Ticker.fast_info) â”‚                â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
  â”‚                         â”‚                                   â”‚
  â”‚                         â–¼                                   â”‚
  â”‚  ğŸ”§ BUILD LIVE FEATURES                                     â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
  â”‚  â”‚ â€¢ Combine with last 1 year of data     â”‚                â”‚
  â”‚  â”‚ â€¢ Calculate RSI, MACD, BB, etc.        â”‚                â”‚
  â”‚  â”‚ â€¢ Calculate volatility, VIX features   â”‚                â”‚
  â”‚  â”‚ â€¢ Result: 60+ features for TODAY       â”‚                â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
  â”‚                         â”‚                                   â”‚
  â”‚                         â–¼                                   â”‚
  â”‚  ğŸ§  LOAD THE BRAIN (Pre-trained Models)                     â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
  â”‚  â”‚ hmm_regime.pkl    â†’ Regime patterns    â”‚                â”‚
  â”‚  â”‚ rf_reversal.pkl   â†’ Reversal patterns  â”‚                â”‚
  â”‚  â”‚ xgb_momentum.pkl  â†’ Momentum patterns  â”‚                â”‚
  â”‚  â”‚ qr_range.pkl      â†’ Range patterns     â”‚                â”‚
  â”‚  â”‚ gbm_divergence.pklâ†’ Divergence patternsâ”‚                â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
  â”‚                         â”‚                                   â”‚
  â”‚                         â–¼                                   â”‚
  â”‚  ğŸ”„ MIX: Feed Today's Features to Brain                     â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
  â”‚  â”‚ today_features = [rsi=68, macd=+15,    â”‚                â”‚
  â”‚  â”‚                   vix=12.35, streak=2, â”‚                â”‚
  â”‚  â”‚                   volatility=0.011...] â”‚                â”‚
  â”‚  â”‚                                         â”‚                â”‚
  â”‚  â”‚ predictions = brain.predict(today)      â”‚                â”‚
  â”‚  â”‚                                         â”‚                â”‚
  â”‚  â”‚ # Brain says:                           â”‚                â”‚
  â”‚  â”‚ # "I've seen this pattern before..."    â”‚                â”‚
  â”‚  â”‚ # "RSI=68 + VIX=12 + streak=2 usually   â”‚                â”‚
  â”‚  â”‚ #  means TRENDING regime with 72% prob" â”‚                â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
  â”‚                         â”‚                                   â”‚
  â”‚                         â–¼                                   â”‚
  â”‚  ğŸ“Š GENERATE PREDICTIONS                                    â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
  â”‚  â”‚ {                                       â”‚                â”‚
  â”‚  â”‚   "regime": "TRENDING",                 â”‚                â”‚
  â”‚  â”‚   "regime_probability": 0.72,           â”‚                â”‚
  â”‚  â”‚   "reversal_probability": 0.35,         â”‚                â”‚
  â”‚  â”‚   "momentum_score": 68,                 â”‚                â”‚
  â”‚  â”‚   "range_q50": 245.3,                   â”‚                â”‚
  â”‚  â”‚   ...                                   â”‚                â”‚
  â”‚  â”‚ }                                       â”‚                â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
  â”‚                         â”‚                                   â”‚
  â”‚                         â–¼                                   â”‚
  â”‚  ğŸ–¥ï¸ UPDATE DASHBOARD (16 Tiles)                             â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”    â”‚                â”‚
  â”‚  â”‚ â”‚Regimeâ”‚ â”‚Momentâ”‚ â”‚Range â”‚ â”‚VaR   â”‚    â”‚                â”‚
  â”‚  â”‚ â”‚TREND â”‚ â”‚ 68   â”‚ â”‚Â±245  â”‚ â”‚1.2%  â”‚    â”‚                â”‚
  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜    â”‚                â”‚
  â”‚  â”‚ ... 12 more tiles ...                   â”‚                â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
  â”‚                                                             â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Summary: The Complete Picture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         THE SYSTEM                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  SATURDAY (Once a Week):                                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                            â”‚
â”‚                                                                     â”‚
â”‚  yfinance â”€â”€â”€â–º 20 Years â”€â”€â”€â–º 60+ Features â”€â”€â”€â–º TRAIN â”€â”€â”€â–º BRAIN    â”‚
â”‚  (NIFTY)       OHLCV Data    per day           5 Models   (.pkl)   â”‚
â”‚  (BANKNIFTY)   (~5000 days)                                         â”‚
â”‚  (VIX)                                                              â”‚
â”‚                                                                     â”‚
â”‚                                    â”‚                                â”‚
â”‚                                    â–¼                                â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                              â”‚  BRAIN   â”‚                           â”‚
â”‚                              â”‚ (9.4 MB) â”‚                           â”‚
â”‚                              â”‚ Stored   â”‚                           â”‚
â”‚                              â”‚ in GitHubâ”‚                           â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                    â”‚                                â”‚
â”‚                                    â–¼                                â”‚
â”‚  EVERY 30 MIN (Market Hours):                                       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                      â”‚
â”‚                                                                     â”‚
â”‚  yfinance â”€â”€â”€â–º Live Spot â”€â”€â”€â–º Build Today's â”€â”€â”€â–º MIX WITH â”€â”€â”€â–º JSONâ”‚
â”‚  (NIFTY)       Prices         Features (60+)     BRAIN             â”‚
â”‚  (BANKNIFTY)   (current)                                            â”‚
â”‚  (VIX)                                                              â”‚
â”‚                                                        â”‚            â”‚
â”‚                                                        â–¼            â”‚
â”‚                                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                                                   â”‚DASHBOARD â”‚      â”‚
â”‚                                                   â”‚16 Tiles  â”‚      â”‚
â”‚                                                   â”‚Updated   â”‚      â”‚
â”‚                                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ML Model Inventory

| # | Model Name | Algorithm | Purpose | Tile Used In | File Size |
|---|------------|-----------|---------|--------------|-----------|
| 1 | **HMM Regime Detector** | Hidden Markov Model (Gaussian Emissions) | Classify market regime (Trending/Mean-Reverting/Chaotic) | Regime Beacon | ~1.2 MB |
| 2 | **RF Streak Reversal** | Random Forest Classifier | Predict reversal after consecutive up/down days | Streak Reversal | ~2.5 MB |
| 3 | **XGB Momentum Pulse** | XGBoost Gradient Boosting | Score momentum strength (0-100) | Momentum Pulse | ~3.1 MB |
| 4 | **QR Range Predictor** | Quantile Regression (Linear) | Predict Q10/Q25/Q50/Q75/Q90 price ranges | Range Quartiles | ~0.8 MB |
| 5 | **GBM Divergence Detector** | Gradient Boosting Machine | Detect RSI/MACD/Price divergences | Momentum Pulse | ~1.8 MB |

**Total Model Size**: ~9.4 MB (fits easily in GitHub repo)

---

### Training Data Source (yfinance ONLY)

```mermaid
graph TB
    subgraph "yfinance Downloads"
        YF1["yfinance.download('^NSEI')<br/>NIFTY 50 Index"]
        YF2["yfinance.download('^NSEBANK')<br/>BANKNIFTY Index"]
        YF3["yfinance.download('^INDIAVIX')<br/>India VIX"]
    end
    
    subgraph "Data Range"
        DR["2005 â†’ Present<br/>~20 Years<br/>~5,000 Trading Days"]
    end
    
    subgraph "OHLCV Columns"
        O["Open"]
        H["High"]
        L["Low"]
        C["Close"]
        V["Volume"]
    end
    
    YF1 --> DR
    YF2 --> DR
    YF3 --> DR
    DR --> O
    DR --> H
    DR --> L
    DR --> C
    DR --> V
    
    style YF1 fill:#3b82f6
    style YF2 fill:#10b981
    style YF3 fill:#f59e0b
```

### Data Fetching Code

```python
import yfinance as yf
import pandas as pd
from datetime import datetime

def fetch_training_data():
    """
    Fetch NIFTY, BANKNIFTY, VIX data from 2005 using yfinance
    This is the SOLE source of truth - no other data sources
    """
    # NIFTY 50 Index
    nifty = yf.download(
        "^NSEI",
        start="2005-01-01",
        end=datetime.now().strftime("%Y-%m-%d"),
        progress=False
    )
    
    # BANKNIFTY Index
    banknifty = yf.download(
        "^NSEBANK",
        start="2005-01-01",
        end=datetime.now().strftime("%Y-%m-%d"),
        progress=False
    )
    
    # India VIX (available from 2008)
    vix = yf.download(
        "^INDIAVIX",
        start="2008-01-01",
        end=datetime.now().strftime("%Y-%m-%d"),
        progress=False
    )
    
    # Save to CSV for caching
    nifty.to_csv("data/NSEI_daily.csv")
    banknifty.to_csv("data/NSEBANK_daily.csv")
    vix.to_csv("data/INDIAVIX_daily.csv")
    
    return nifty, banknifty, vix
```

---

### Training Frequency

| Schedule | Frequency | What Happens | GitHub Actions |
|----------|-----------|--------------|----------------|
| **Weekly Training** | Every **Saturday 00:00 UTC** | Full model retraining on all historical data | `weekly_training.yml` |
| **Daily Inference** | Every **30 min** (M-F 9:15 AM - 3:30 PM IST) | Load trained models, run predictions | `daily_inference.yml` |

```mermaid
graph LR
    subgraph "WEEKLY (Saturdays)"
        W1["Fetch Full History<br/>2005 â†’ Now"] --> W2["Feature Engineering<br/>60+ Features"]
        W2 --> W3["Train 5 Models"]
        W3 --> W4["Save .pkl Files<br/>to models/"]
        W4 --> W5["Commit to GitHub"]
    end
    
    subgraph "DAILY (Every 30min M-F)"
        D1["Load .pkl Models"] --> D2["Fetch Recent 1Y Data"]
        D2 --> D3["Build Live Features"]
        D3 --> D4["Run Inference"]
        D4 --> D5["Generate JSON"]
        D5 --> D6["Deploy Dashboard"]
    end
    
    W5 -.->|"Models Updated Weekly"| D1
    
    style W3 fill:#f59e0b
    style D4 fill:#10b981
```

---

### Feature Engineering Pipeline

All ML models use features derived from **OHLCV + VIX** data:

```python
def build_features(nifty_df: pd.DataFrame, vix_df: pd.DataFrame) -> pd.DataFrame:
    """
    Build 60+ features from raw OHLCV and VIX data
    These features feed into all 5 ML models
    """
    df = nifty_df.copy()
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PRICE-BASED FEATURES (from OHLCV)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Daily Returns
    df['return_1d'] = df['Close'].pct_change(1)
    df['return_5d'] = df['Close'].pct_change(5)
    df['return_20d'] = df['Close'].pct_change(20)
    
    # Log Returns (for statistical models)
    df['log_return'] = np.log(df['Close'] / df['Close'].shift(1))
    
    # Volatility (Rolling Std of Returns)
    df['volatility_10d'] = df['return_1d'].rolling(10).std() * np.sqrt(252)
    df['volatility_20d'] = df['return_1d'].rolling(20).std() * np.sqrt(252)
    df['volatility_60d'] = df['return_1d'].rolling(60).std() * np.sqrt(252)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TECHNICAL INDICATORS (from OHLCV)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # RSI (Relative Strength Index)
    delta = df['Close'].diff()
    gain = delta.clip(lower=0).rolling(14).mean()
    loss = (-delta.clip(upper=0)).rolling(14).mean()
    df['rsi_14'] = 100 - (100 / (1 + gain / (loss + 1e-10)))
    
    # MACD
    ema_12 = df['Close'].ewm(span=12).mean()
    ema_26 = df['Close'].ewm(span=26).mean()
    df['macd'] = ema_12 - ema_26
    df['macd_signal'] = df['macd'].ewm(span=9).mean()
    df['macd_histogram'] = df['macd'] - df['macd_signal']
    
    # Bollinger Bands
    df['bb_middle'] = df['Close'].rolling(20).mean()
    df['bb_std'] = df['Close'].rolling(20).std()
    df['bb_upper'] = df['bb_middle'] + 2 * df['bb_std']
    df['bb_lower'] = df['bb_middle'] - 2 * df['bb_std']
    df['bb_position'] = (df['Close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-10)
    
    # ATR (Average True Range)
    high_low = df['High'] - df['Low']
    high_close = abs(df['High'] - df['Close'].shift(1))
    low_close = abs(df['Low'] - df['Close'].shift(1))
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['atr_14'] = tr.rolling(14).mean()
    df['atr_pct'] = df['atr_14'] / df['Close']
    
    # Moving Averages
    df['sma_5'] = df['Close'].rolling(5).mean()
    df['sma_20'] = df['Close'].rolling(20).mean()
    df['sma_50'] = df['Close'].rolling(50).mean()
    df['sma_200'] = df['Close'].rolling(200).mean()
    
    # Price vs Moving Averages
    df['price_vs_sma20'] = (df['Close'] - df['sma_20']) / df['sma_20']
    df['price_vs_sma50'] = (df['Close'] - df['sma_50']) / df['sma_50']
    df['price_vs_sma200'] = (df['Close'] - df['sma_200']) / df['sma_200']
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STREAK FEATURES (for Reversal Model)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Consecutive up/down days
    df['up_day'] = (df['return_1d'] > 0).astype(int)
    df['down_day'] = (df['return_1d'] < 0).astype(int)
    
    # Streak counter
    df['streak'] = df['up_day'].groupby(
        (df['up_day'] != df['up_day'].shift()).cumsum()
    ).cumsum() - df['down_day'].groupby(
        (df['down_day'] != df['down_day'].shift()).cumsum()
    ).cumsum()
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # VIX FEATURES (from India VIX)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Merge VIX data
    df['vix'] = vix_df['Close'].reindex(df.index).ffill()
    df['vix_5d_avg'] = df['vix'].rolling(5).mean()
    df['vix_20d_avg'] = df['vix'].rolling(20).mean()
    df['vix_percentile'] = df['vix'].rolling(252).rank(pct=True)
    
    # VIX Term Structure (proxy using short vs long avg)
    df['vix_term_structure'] = (df['vix_20d_avg'] - df['vix_5d_avg']) / (df['vix_20d_avg'] + 1e-10)
    
    # VIX vs Price Relationship
    df['vix_price_corr'] = df['vix'].rolling(20).corr(df['Close'])
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # VOLUME FEATURES (from OHLCV)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    df['volume_sma_20'] = df['Volume'].rolling(20).mean()
    df['volume_ratio'] = df['Volume'] / (df['volume_sma_20'] + 1e-10)
    df['volume_change'] = df['Volume'].pct_change()
    
    # Drop NaN rows
    df = df.dropna()
    
    return df
```

---

### Model #1: HMM Regime Detector

**Algorithm**: Hidden Markov Model with Gaussian Emissions  
**Training Frequency**: Weekly (Saturdays)  
**Used In**: Regime Beacon Tile

```python
from hmmlearn import hmm
import numpy as np
import joblib

def train_hmm_regime(features_df: pd.DataFrame):
    """
    Train Hidden Markov Model for market regime detection
    
    States:
        0: TRENDING (low vol, strong direction)
        1: MEAN-REVERTING (medium vol, oscillating)
        2: CHAOTIC (high vol, unpredictable)
    """
    # Use returns and volatility as observations
    observations = features_df[['return_1d', 'volatility_20d']].values
    
    # Initialize HMM with 3 hidden states
    model = hmm.GaussianHMM(
        n_components=3,           # 3 regimes
        covariance_type="full",   # Full covariance matrix
        n_iter=1000,              # Max iterations
        random_state=42,
        verbose=False
    )
    
    # Train on historical data
    model.fit(observations)
    
    # Get state sequence and probabilities
    hidden_states = model.predict(observations)
    state_probs = model.predict_proba(observations)
    
    # Label states based on learned means
    # State with highest volatility mean = CHAOTIC
    # State with lowest volatility mean = TRENDING
    vol_means = [model.means_[i][1] for i in range(3)]
    state_labels = [''] * 3
    state_labels[np.argmax(vol_means)] = 'CHAOTIC'
    state_labels[np.argmin(vol_means)] = 'TRENDING'
    remaining = [i for i in range(3) if state_labels[i] == ''][0]
    state_labels[remaining] = 'MEAN_REVERTING'
    
    # Save model
    joblib.dump({
        'model': model,
        'state_labels': state_labels,
        'scaler_mean': observations.mean(axis=0),
        'scaler_std': observations.std(axis=0)
    }, 'models/hmm_regime.pkl')
    
    print(f"HMM Regime Model trained on {len(observations)} samples")
    return model, state_labels
```

**Inference (Every 30 min)**:
```python
def infer_regime(features_df: pd.DataFrame):
    """Run regime inference using pre-trained HMM"""
    data = joblib.load('models/hmm_regime.pkl')
    model = data['model']
    state_labels = data['state_labels']
    
    # Get latest observation
    latest = features_df[['return_1d', 'volatility_20d']].iloc[-1:].values
    
    # Predict regime
    state = model.predict(latest)[0]
    probs = model.predict_proba(latest)[0]
    
    return {
        'regime': state_labels[state],
        'regime_probability': float(probs[state]),
        'all_probabilities': {
            state_labels[i]: float(probs[i]) for i in range(3)
        }
    }
```

---

### Model #2: Random Forest Streak Reversal

**Algorithm**: Random Forest Classifier  
**Training Frequency**: Weekly (Saturdays)  
**Used In**: Streak Reversal Tile

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import joblib

def train_rf_reversal(features_df: pd.DataFrame):
    """
    Train Random Forest to predict streak reversal
    
    Target: Will tomorrow reverse the current streak?
    Features: Streak length, RSI, VIX, volatility, etc.
    """
    df = features_df.copy()
    
    # Create target: Did the streak reverse next day?
    df['streak_sign'] = np.sign(df['streak'])
    df['next_return_sign'] = np.sign(df['return_1d'].shift(-1))
    df['reversal'] = (df['streak_sign'] != df['next_return_sign']).astype(int)
    
    # Features for reversal prediction
    feature_cols = [
        'streak', 'rsi_14', 'bb_position', 'macd_histogram',
        'volatility_20d', 'vix', 'vix_percentile',
        'atr_pct', 'volume_ratio', 'price_vs_sma20'
    ]
    
    # Remove last row (no target) and NaNs
    df = df.dropna()
    X = df[feature_cols].iloc[:-1]
    y = df['reversal'].iloc[:-1]
    
    # Train-test split (80/20)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, shuffle=False
    )
    
    # Train Random Forest
    model = RandomForestClassifier(
        n_estimators=200,
        max_depth=10,
        min_samples_split=20,
        min_samples_leaf=10,
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train, y_train)
    
    # Evaluate
    train_acc = model.score(X_train, y_train)
    test_acc = model.score(X_test, y_test)
    print(f"RF Reversal - Train: {train_acc:.2%}, Test: {test_acc:.2%}")
    
    # Save model
    joblib.dump({
        'model': model,
        'feature_cols': feature_cols
    }, 'models/rf_reversal.pkl')
    
    return model
```

---

### Model #3: XGBoost Momentum Pulse

**Algorithm**: XGBoost Gradient Boosting  
**Training Frequency**: Weekly (Saturdays)  
**Used In**: Momentum Pulse Tile

```python
from xgboost import XGBClassifier
import joblib

def train_xgb_momentum(features_df: pd.DataFrame):
    """
    Train XGBoost to score momentum strength
    
    Target: Strong momentum (>1.5% move) in next 3 days
    Output: Probability score 0-100
    """
    df = features_df.copy()
    
    # Target: Strong directional move in next 3 days
    df['future_3d_return'] = df['Close'].shift(-3) / df['Close'] - 1
    df['strong_momentum'] = (abs(df['future_3d_return']) > 0.015).astype(int)
    
    feature_cols = [
        'rsi_14', 'macd', 'macd_histogram', 'bb_position',
        'return_1d', 'return_5d', 'return_20d',
        'volatility_10d', 'volatility_20d',
        'atr_pct', 'volume_ratio',
        'price_vs_sma20', 'price_vs_sma50',
        'vix', 'vix_percentile', 'vix_term_structure'
    ]
    
    df = df.dropna()
    X = df[feature_cols].iloc[:-3]
    y = df['strong_momentum'].iloc[:-3]
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, shuffle=False
    )
    
    model = XGBClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        use_label_encoder=False,
        eval_metric='logloss'
    )
    model.fit(X_train, y_train)
    
    test_acc = model.score(X_test, y_test)
    print(f"XGB Momentum - Test Accuracy: {test_acc:.2%}")
    
    joblib.dump({
        'model': model,
        'feature_cols': feature_cols
    }, 'models/xgb_momentum.pkl')
    
    return model
```

---

### Model #4: Quantile Regression Range Predictor

**Algorithm**: Linear Quantile Regression  
**Training Frequency**: Weekly (Saturdays)  
**Used In**: Range Quartiles Tile

```python
from sklearn.linear_model import QuantileRegressor
import joblib

def train_qr_range(features_df: pd.DataFrame):
    """
    Train Quantile Regression for price range prediction
    
    Predicts Q10, Q25, Q50, Q75, Q90 of next-day price range
    """
    df = features_df.copy()
    
    # Target: Next-day range as % of close
    df['next_range'] = (df['High'].shift(-1) - df['Low'].shift(-1)) / df['Close']
    
    feature_cols = [
        'atr_pct', 'volatility_10d', 'volatility_20d',
        'vix', 'vix_percentile', 'volume_ratio',
        'bb_position', 'rsi_14'
    ]
    
    df = df.dropna()
    X = df[feature_cols].iloc[:-1]
    y = df['next_range'].iloc[:-1]
    
    # Train separate models for each quantile
    quantiles = [0.10, 0.25, 0.50, 0.75, 0.90]
    models = {}
    
    for q in quantiles:
        model = QuantileRegressor(
            quantile=q,
            alpha=0.01,
            solver='highs'
        )
        model.fit(X, y)
        models[f'q{int(q*100)}'] = model
        print(f"Quantile {q:.0%} model trained")
    
    joblib.dump({
        'models': models,
        'feature_cols': feature_cols
    }, 'models/qr_range.pkl')
    
    return models
```

---

### Model #5: Gradient Boosting Divergence Detector

**Algorithm**: Gradient Boosting Machine  
**Training Frequency**: Weekly (Saturdays)  
**Used In**: Momentum Pulse Tile (sub-component)

```python
from sklearn.ensemble import GradientBoostingClassifier
import joblib

def train_gbm_divergence(features_df: pd.DataFrame):
    """
    Train GBM to detect RSI/MACD divergences
    
    Bullish Divergence: Price makes lower low, RSI makes higher low
    Bearish Divergence: Price makes higher high, RSI makes lower high
    """
    df = features_df.copy()
    
    # Detect divergence patterns
    df['price_5d_min'] = df['Close'].rolling(5).min()
    df['price_5d_max'] = df['Close'].rolling(5).max()
    df['rsi_5d_min'] = df['rsi_14'].rolling(5).min()
    df['rsi_5d_max'] = df['rsi_14'].rolling(5).max()
    
    # Bullish divergence: price lower low, RSI higher low
    df['bullish_div'] = (
        (df['price_5d_min'] < df['price_5d_min'].shift(5)) &
        (df['rsi_5d_min'] > df['rsi_5d_min'].shift(5))
    ).astype(int)
    
    # Bearish divergence: price higher high, RSI lower high
    df['bearish_div'] = (
        (df['price_5d_max'] > df['price_5d_max'].shift(5)) &
        (df['rsi_5d_max'] < df['rsi_5d_max'].shift(5))
    ).astype(int)
    
    # Target: Any divergence
    df['divergence'] = (df['bullish_div'] | df['bearish_div']).astype(int)
    
    feature_cols = [
        'rsi_14', 'macd', 'macd_histogram',
        'return_5d', 'return_20d',
        'bb_position', 'volume_ratio'
    ]
    
    df = df.dropna()
    X = df[feature_cols]
    y = df['divergence']
    
    model = GradientBoostingClassifier(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.1,
        random_state=42
    )
    model.fit(X, y)
    
    joblib.dump({
        'model': model,
        'feature_cols': feature_cols
    }, 'models/gbm_divergence.pkl')
    
    return model
```

---

### Complete Training Script (train_all_models.py)

```python
#!/usr/bin/env python3
"""
Omega Vault - Weekly Model Training Script
Runs every Saturday via GitHub Actions

Data Source: yfinance (NIFTY, BANKNIFTY, VIX from 2005)
Output: 5 trained models saved to models/
"""

import os
import sys
import yfinance as yf
import pandas as pd
from datetime import datetime

# Import all training functions
from models.hmm_regime import train_hmm_regime
from models.rf_reversal import train_rf_reversal
from models.xgb_momentum import train_xgb_momentum
from models.qr_range import train_qr_range
from models.gbm_divergence import train_gbm_divergence
from features.feature_builder import build_features

def main():
    print("=" * 60)
    print("OMEGA VAULT - WEEKLY MODEL TRAINING")
    print(f"Started at: {datetime.now().isoformat()}")
    print("=" * 60)
    
    # Step 1: Fetch Historical Data
    print("\n[1/6] Fetching historical data from yfinance...")
    
    nifty = yf.download("^NSEI", start="2005-01-01", progress=True)
    print(f"  NIFTY: {len(nifty)} rows ({nifty.index[0]} to {nifty.index[-1]})")
    
    banknifty = yf.download("^NSEBANK", start="2005-01-01", progress=True)
    print(f"  BANKNIFTY: {len(banknifty)} rows")
    
    vix = yf.download("^INDIAVIX", start="2008-01-01", progress=True)
    print(f"  VIX: {len(vix)} rows")
    
    # Step 2: Build Features
    print("\n[2/6] Building features from OHLCV + VIX data...")
    features_df = build_features(nifty, vix)
    print(f"  Generated {len(features_df.columns)} features")
    print(f"  Training samples: {len(features_df)}")
    
    # Step 3: Train HMM Regime
    print("\n[3/6] Training HMM Regime Detector...")
    train_hmm_regime(features_df)
    
    # Step 4: Train RF Reversal
    print("\n[4/6] Training Random Forest Reversal...")
    train_rf_reversal(features_df)
    
    # Step 5: Train XGB Momentum
    print("\n[5/6] Training XGBoost Momentum...")
    train_xgb_momentum(features_df)
    
    # Step 6: Train QR Range
    print("\n[6/6] Training Quantile Regression Range...")
    train_qr_range(features_df)
    
    # Step 7: Train GBM Divergence
    print("\n[7/7] Training GBM Divergence...")
    train_gbm_divergence(features_df)
    
    print("\n" + "=" * 60)
    print("TRAINING COMPLETE!")
    print(f"Models saved to: models/")
    print(f"Finished at: {datetime.now().isoformat()}")
    print("=" * 60)

if __name__ == "__main__":
    main()
```

---

### Inference Script (infer.py)

```python
#!/usr/bin/env python3
"""
Omega Vault - Daily Inference Script
Runs every 30 min (M-F 9:15 AM - 3:30 PM IST)

Loads pre-trained models, fetches live data, generates predictions
Output: omega_vault.json for dashboard
"""

import os
import json
import joblib
import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime

from features.feature_builder import build_features

def load_all_models():
    """Load all pre-trained models from models/ directory"""
    models = {
        'hmm_regime': joblib.load('models/hmm_regime.pkl'),
        'rf_reversal': joblib.load('models/rf_reversal.pkl'),
        'xgb_momentum': joblib.load('models/xgb_momentum.pkl'),
        'qr_range': joblib.load('models/qr_range.pkl'),
        'gbm_divergence': joblib.load('models/gbm_divergence.pkl')
    }
    print(f"Loaded {len(models)} models")
    return models

def fetch_live_data():
    """Fetch recent 1-year data + live price"""
    nifty = yf.download("^NSEI", period="1y", progress=False)
    vix = yf.download("^INDIAVIX", period="1y", progress=False)
    
    # Get live spot price
    ticker = yf.Ticker("^NSEI")
    live_price = ticker.fast_info.get('lastPrice', nifty['Close'].iloc[-1])
    
    return nifty, vix, live_price

def run_inference(models, features_df, live_price):
    """Run all model predictions"""
    latest = features_df.iloc[-1:]
    
    results = {
        'generated_at': datetime.now().isoformat(),
        'spot_price': float(live_price),
        'predictions': {}
    }
    
    # 1. Regime Prediction
    hmm_data = models['hmm_regime']
    obs = latest[['return_1d', 'volatility_20d']].values
    state = hmm_data['model'].predict(obs)[0]
    probs = hmm_data['model'].predict_proba(obs)[0]
    results['predictions']['regime'] = {
        'current': hmm_data['state_labels'][state],
        'probability': float(probs[state]),
        'all_probs': {hmm_data['state_labels'][i]: float(probs[i]) for i in range(3)}
    }
    
    # 2. Reversal Prediction
    rf_data = models['rf_reversal']
    X_rev = latest[rf_data['feature_cols']]
    rev_prob = rf_data['model'].predict_proba(X_rev)[0][1]
    results['predictions']['reversal'] = {
        'probability': float(rev_prob),
        'current_streak': int(latest['streak'].iloc[0])
    }
    
    # 3. Momentum Score
    xgb_data = models['xgb_momentum']
    X_mom = latest[xgb_data['feature_cols']]
    mom_prob = xgb_data['model'].predict_proba(X_mom)[0][1]
    results['predictions']['momentum'] = {
        'score': int(mom_prob * 100),
        'strength': 'HIGH' if mom_prob > 0.7 else 'MEDIUM' if mom_prob > 0.4 else 'LOW'
    }
    
    # 4. Range Quartiles
    qr_data = models['qr_range']
    X_range = latest[qr_data['feature_cols']]
    range_preds = {}
    for q_name, qr_model in qr_data['models'].items():
        range_preds[q_name] = float(qr_model.predict(X_range)[0] * live_price)
    results['predictions']['range'] = range_preds
    
    return results

def main():
    print("Omega Vault - Inference Run")
    print(f"Time: {datetime.now().isoformat()}")
    
    # Load models
    models = load_all_models()
    
    # Fetch data
    nifty, vix, live_price = fetch_live_data()
    print(f"Live Price: {live_price}")
    
    # Build features
    features_df = build_features(nifty, vix)
    
    # Run inference
    results = run_inference(models, features_df, live_price)
    
    # Save to JSON
    with open('client/public/data/omega_vault.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print("Inference complete! Results saved to omega_vault.json")

if __name__ == "__main__":
    main()
```

---

### Model Files Structure

```
models/
â”œâ”€â”€ hmm_regime.pkl           # Hidden Markov Model (1.2 MB)
â”‚   â”œâ”€â”€ model               # Trained HMM object
â”‚   â”œâ”€â”€ state_labels        # ['TRENDING', 'MEAN_REVERTING', 'CHAOTIC']
â”‚   â””â”€â”€ scaler_params       # Normalization parameters
â”‚
â”œâ”€â”€ rf_reversal.pkl          # Random Forest (2.5 MB)
â”‚   â”œâ”€â”€ model               # 200 decision trees
â”‚   â””â”€â”€ feature_cols        # List of feature names
â”‚
â”œâ”€â”€ xgb_momentum.pkl         # XGBoost (3.1 MB)
â”‚   â”œâ”€â”€ model               # 200 gradient boosted trees
â”‚   â””â”€â”€ feature_cols        # List of feature names
â”‚
â”œâ”€â”€ qr_range.pkl             # Quantile Regression (0.8 MB)
â”‚   â”œâ”€â”€ models              # Dict of 5 quantile models (Q10-Q90)
â”‚   â””â”€â”€ feature_cols        # List of feature names
â”‚
â””â”€â”€ gbm_divergence.pkl       # Gradient Boosting (1.8 MB)
    â”œâ”€â”€ model               # 100 boosted trees
    â””â”€â”€ feature_cols        # List of feature names

Total: ~9.4 MB
```

---

### GitHub Actions Workflow (weekly_training.yml)

```yaml
name: Weekly Model Training

on:
  schedule:
    # Every Saturday at 00:00 UTC (5:30 AM IST)
    - cron: '0 0 * * 6'
  workflow_dispatch:  # Manual trigger

jobs:
  train:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Setup Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install Dependencies
        run: pip install -r engine/requirements.txt
      
      - name: Run Training Script
        run: python engine/scripts/train_all_models.py
      
      - name: Commit Trained Models
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add models/*.pkl
          git commit -m "chore: weekly model retraining [skip ci]" || exit 0
          git push
```

---

## ğŸ“ Institutional Formulas Used

### A. Goldman Sachs Style - Probability Models

#### 1. **Black-Scholes-Merton Probability of Breach**
```python
# Probability of price touching a barrier level
from scipy.stats import norm
import numpy as np

def prob_touch_barrier(spot, barrier, sigma, T, r=0.05):
    """
    Goldman Sachs barrier option pricing methodology
    Used for calculating probability of price reaching a level
    """
    mu = r - 0.5 * sigma**2
    barrier_distance = np.log(barrier / spot)
    lambda_param = mu / sigma**2
    
    d1 = (np.log(spot / barrier) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))
    d2 = d1 - sigma * np.sqrt(T)
    
    # First passage time probability
    prob = norm.cdf(-d2) + (barrier/spot)**(2*lambda_param) * norm.cdf(-d1 + 2*lambda_param*sigma*np.sqrt(T))
    
    return np.clip(prob, 0, 1)
```

#### 2. **Jump-Diffusion Model (Merton, 1976)**
```python
# Models sudden market gaps (critical for Indian markets post-US closes)
import numpy as np

def merton_jump_diffusion_simulation(S0, r, sigma, lambda_j, mu_j, sigma_j, T, n_paths=10000):
    """
    Merton (1976) Jump-Diffusion Model
    - sigma: continuous volatility
    - lambda_j: jump intensity (avg jumps per year)
    - mu_j, sigma_j: jump size parameters
    """
    dt = T
    n_jumps = np.random.poisson(lambda_j * T, n_paths)
    jump_sizes = np.sum([np.random.normal(mu_j, sigma_j, n_paths) for _ in range(max(n_jumps))], axis=0)
    
    drift = (r - 0.5 * sigma**2 - lambda_j * (np.exp(mu_j + 0.5*sigma_j**2) - 1)) * T
    diffusion = sigma * np.sqrt(T) * np.random.normal(0, 1, n_paths)
    
    ST = S0 * np.exp(drift + diffusion + jump_sizes)
    return ST
```

### B. BlackRock Style - Risk Management

#### 3. **Conditional Value at Risk (CVaR / Expected Shortfall)**
```python
# BlackRock Aladdin-style tail risk quantification
import numpy as np

def calculate_cvar(returns, confidence=0.95):
    """
    CVaR / Expected Shortfall - Average loss beyond VaR
    BlackRock uses this for portfolio stress testing
    """
    var = np.percentile(returns, (1 - confidence) * 100)
    cvar = returns[returns <= var].mean()
    return var, cvar
```

#### 4. **Kelly Criterion Position Sizing**
```python
# Optimal bankroll allocation per trade
def kelly_criterion(win_rate, avg_win, avg_loss):
    """
    Kelly Criterion: f* = (p * b - q) / b
    where:
    - p = win probability
    - q = 1 - p
    - b = win/loss ratio
    """
    if avg_loss == 0:
        return 0.25  # Default conservative
    
    b = avg_win / abs(avg_loss)
    f_star = (win_rate * b - (1 - win_rate)) / b
    
    # Use fractional Kelly (1/4) for conservatism
    return np.clip(f_star * 0.25, 0.05, 0.25)
```

### C. DE Shaw / Renaissance Style - Statistical Edge

#### 5. **Hidden Markov Model Regime Detection**
```python
# Market regime classification using probabilistic graphical models
from hmmlearn import hmm
import numpy as np

def train_regime_hmm(returns, n_states=3):
    """
    Hidden Markov Model for regime detection
    States: 0=Trending, 1=Mean-Reverting, 2=Chaotic
    """
    model = hmm.GaussianHMM(
        n_components=n_states,
        covariance_type="full",
        n_iter=1000,
        random_state=42
    )
    
    X = returns.values.reshape(-1, 1)
    model.fit(X)
    
    hidden_states = model.predict(X)
    state_probabilities = model.predict_proba(X)
    
    return model, hidden_states, state_probabilities
```

#### 6. **Hurst Exponent for Trend Persistence**
```python
# Measures whether market is trending or mean-reverting
import numpy as np

def calculate_hurst_exponent(prices, max_lag=100):
    """
    Hurst Exponent using R/S Analysis
    H > 0.5: Trending (momentum works)
    H < 0.5: Mean-reverting (contrarian works)
    H = 0.5: Random walk
    """
    lags = range(2, max_lag)
    tau = [np.std(np.subtract(prices[lag:], prices[:-lag])) for lag in lags]
    
    # Linear fit in log-log space
    poly = np.polyfit(np.log(lags), np.log(tau), 1)
    H = poly[0]
    
    return np.clip(H, 0, 1)
```

### D. Citadel / Two Sigma Style - Options Greeks

#### 7. **Gamma Exposure (GEX) Estimation**
```python
# Dealer positioning proxy using volume patterns
def estimate_gamma_exposure(volume_series, price_series, atm_strike):
    """
    Gamma Exposure estimation using volume as proxy
    (No real OI data from yfinance, so we use volume patterns)
    """
    recent_volume = volume_series[-5:].mean()
    historical_volume = volume_series[-60:].mean()
    
    volume_ratio = recent_volume / (historical_volume + 1e-6)
    price_distance = abs(price_series.iloc[-1] - atm_strike) / atm_strike
    
    # Positive GEX = Dealers likely short gamma (dampening)
    # Negative GEX = Dealers likely long gamma (amplifying)
    gex_proxy = (volume_ratio - 1) * (1 - price_distance)
    
    return gex_proxy * 100  # Scale to -100 to +100
```

#### 8. **VIX Term Structure Analysis**
```python
# Contango/Backwardation detection for VIX futures proxy
def vix_term_structure_signal(vix_current, vix_20d_avg, vix_5d_avg):
    """
    VIX Term Structure using historical VIX as proxy
    - Contango: Near-term VIX < Longer-term (normal, sell premium)
    - Backwardation: Near-term VIX > Longer-term (stressed, buy protection)
    """
    short_term = vix_5d_avg
    long_term = vix_20d_avg
    
    term_structure = (long_term - short_term) / (long_term + 1e-6)
    
    if term_structure > 0.05:
        regime = "CONTANGO"
        signal = "SELL_PREMIUM"
    elif term_structure < -0.05:
        regime = "BACKWARDATION"
        signal = "BUY_PROTECTION"
    else:
        regime = "FLAT"
        signal = "NEUTRAL"
    
    return regime, signal, term_structure * 100
```

---

## ğŸ¨ Dashboard Tiles (20 Total)

### Tile Grid Layout (5x4 Grid + Verdict Hero)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ğŸŒŒ OMEGA VAULT HERO SECTION                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   VERDICT: BULLISH EDGE DETECTED                            â”‚    â”‚
â”‚  â”‚   Probability: 67.3% | Kelly Size: 18% | Risk: LOW          â”‚    â”‚
â”‚  â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 67.3%                             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“˜ HOW TO USE THIS DASHBOARD (Click to Expand Guide)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TILE 1         â”‚  TILE 2         â”‚  TILE 3         â”‚  TILE 4       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   Spot    â”‚  â”‚  â”‚   India   â”‚  â”‚  â”‚ Probability â”‚  â”‚  â”‚  Regime   â”‚â”‚
â”‚  â”‚   Price   â”‚  â”‚  â”‚    VIX    â”‚  â”‚  â”‚   Surface   â”‚  â”‚  â”‚  Beacon   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TILE 5         â”‚  TILE 6         â”‚  TILE 7         â”‚  TILE 8       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   Kelly   â”‚  â”‚  â”‚    VaR    â”‚  â”‚  â”‚   Hurst   â”‚  â”‚  â”‚  VIX Term â”‚â”‚
â”‚  â”‚  Optimal  â”‚  â”‚  â”‚   Gauge   â”‚  â”‚  â”‚  Compass  â”‚  â”‚  â”‚  Contour  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TILE 9         â”‚  TILE 10        â”‚  TILE 11        â”‚  TILE 12      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Friday   â”‚  â”‚  â”‚   Theta   â”‚  â”‚  â”‚   Monte   â”‚  â”‚  â”‚  Barrier  â”‚â”‚
â”‚  â”‚   Fear    â”‚  â”‚  â”‚   Decay   â”‚  â”‚  â”‚   Carlo   â”‚  â”‚  â”‚  Breach   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TILE 13        â”‚  TILE 14        â”‚  TILE 15        â”‚  TILE 16      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   Streak  â”‚  â”‚  â”‚   Pain    â”‚  â”‚  â”‚   Range   â”‚  â”‚  â”‚  Momentum â”‚â”‚
â”‚  â”‚  Reversal â”‚  â”‚  â”‚   Zone    â”‚  â”‚  â”‚ Quartiles â”‚  â”‚  â”‚   Pulse   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TILE 17        â”‚  TILE 18        â”‚  TILE 19        â”‚  TILE 20      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚    GEX    â”‚  â”‚  â”‚   Event   â”‚  â”‚  â”‚  Traffic  â”‚  â”‚  â”‚   FOMO    â”‚â”‚
â”‚  â”‚  Cluster  â”‚  â”‚  â”‚   Radar   â”‚  â”‚  â”‚   Light   â”‚  â”‚  â”‚   Meter   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Complete Tile Specifications

### TILE 1: Spot Price Reference ğŸ¯ {NEW}
**Category**: Market Data  
**Formula Type**: Live Feed  
**ML Required**: âŒ No (Direct API)

**What It Shows**:
- Live NIFTY/BANKNIFTY Spot Price
- Dynamic color change (Green/Red) based on LTP vs Prev Close
- Toggle button to switch between indices
- **Dynamic Verdict**: "Strong Uptrend (+0.4%)" or "Choppy / Sideways"

**User Benefit**: "Instant situational awareness - The anchor for all decisions"

---

### TILE 2: India VIX Monitor ğŸ“‰ {NEW}
**Category**: Volatility  
**Formula Type**: Live Feed  
**ML Required**: âŒ No (Direct API)

**What It Shows**:
- Real-time India VIX value
- Fear Gauge: Low (<12), Normal (12-18), High (>18)
- Intraday % Change
- **Dynamic Verdict**: "Premiums Cheap (Buy)" or "Volatility Spike (Sell)"

**User Benefit**: "Know if premiums are cheap (Buy) or expensive (Sell)"

---

### TILE 3: Probability Surface ğŸ²
**Category**: Probability Engine  
**Formula Type**: Monte Carlo + Bayesian  
**ML Required**: âŒ No (Pure Statistical)

**What It Shows**:
- 3D probability surface for next 5 days
- Color gradient: Green (bullish zones) â†’ Red (bearish zones)
- Contour lines at 25%, 50%, 75% probability levels
- **Dynamic Verdict**: "Skew: Call Side (+2%)" or "Skew: Balanced"

**Formula**:
```python
# 10,000 Monte Carlo paths
paths = merton_jump_diffusion_simulation(spot, r, sigma, lambda_j, mu_j, sigma_j, T)
prob_above_strike = np.mean(paths > strike)
```

**User Benefit**: "See WHERE the price is most likely to go, not just UP or DOWN"

---

### TILE 4: Regime Beacon ğŸš¦
**Category**: Market State  
**Formula Type**: Hidden Markov Model + GARCH  
**ML Required**: âœ… Yes (HMM Training)

**What It Shows**:
- Current market regime with probability
- Transition probabilities to other regimes
- Historical regime timeline (last 20 days)
- **Dynamic Verdict**: "Trending (Good for Buyers)" or "Chaotic (Stay Away)"

**Regimes**:
| Regime | Color | Description | Best Strategy |
|--------|-------|-------------|---------------|
| TRENDING | ğŸŸ¢ Green | Strong directional moves | Directional options |
| MEAN-REVERTING | ğŸŸ¡ Yellow | Price oscillating around mean | Iron condors |
| CHAOTIC | ğŸ”´ Red | High uncertainty, jumps | Stay cash / hedge |

**Formula**: HMM with Gaussian emissions trained on daily returns

---

### TILE 5: Kelly Optimal ğŸ’°
**Category**: Position Sizing  
**Formula Type**: Kelly Criterion  
**ML Required**: âŒ No

**What It Shows**:
- Optimal position size as % of capital
- Full Kelly vs 1/4 Kelly comparison
- Risk-adjusted return expectation

**Display**:
```
Full Kelly: 32%
Quarter Kelly (Recommended): 8%

If Capital = â‚¹10,00,000
Invest: â‚¹80,000 in this trade
```

**User Benefit**: "Know EXACTLY how much to risk, mathematically optimized"

---

### TILE 6: VaR Gauge âš ï¸
**Category**: Risk Management  
**Formula Type**: Historical VaR + CVaR  
**ML Required**: âŒ No

**What It Shows**:
- 95% VaR: "You won't lose more than X with 95% confidence"
- 99% VaR: "Worst-case 1-in-100 days scenario"
- CVaR (Expected Shortfall): "Average loss in tail events"

**Gauge Colors**:
| VaR Level | Color | Interpretation |
|-----------|-------|----------------|
| < 1.5% | ğŸŸ¢ Low Risk | Normal volatility |
| 1.5% - 3% | ğŸŸ¡ Moderate | Elevated caution |
| > 3% | ğŸ”´ High Risk | Reduce position size |

---

### TILE 7: Hurst Compass ğŸ§­
**Category**: Trend Persistence  
**Formula Type**: R/S Analysis  
**ML Required**: âŒ No

**What It Shows**:
- Hurst Exponent value (0 to 1)
- Trend persistence interpretation
- Strategy recommendation

**Quadrants**:
```
           TRENDING
              â†‘
    H > 0.6 = Momentum
              â”‚
REVERTING â†â”€â”€â”€â”¼â”€â”€â”€â†’ RANDOM
              â”‚
    H < 0.4 = Contrarian
              â†“
```

**User Benefit**: "Know if momentum or mean-reversion strategies will work"

---

### TILE 8: VIX Term Contour ğŸ“ˆ
**Category**: Volatility Analysis  
**Formula Type**: Term Structure  
**ML Required**: âŒ No

**What It Shows**:
- VIX term structure visualization
- Contango/Backwardation signal
- Premium selling opportunity window

**Signals**:
| Structure | Signal | Action |
|-----------|--------|--------|
| CONTANGO | ğŸŸ¢ Sell Premium | Write options (theta decay favor) |
| BACKWARDATION | ğŸ”´ Buy Protection | Buy puts (tail risk elevated) |
| FLAT | ğŸŸ¡ Neutral | Normal positioning |

---

### TILE 9: Friday Fear Index ğŸŒ™
**Category**: Gap Risk  
**Formula Type**: Empirical + Statistical  
**ML Required**: âŒ No

**What It Shows**:
- Weekend gap probability
- Historical Friday-to-Monday gap distribution
- Gap size expectation (points)

**Formula**:
```python
# Historical Friday-to-Monday gaps
gaps = monday_open - friday_close
gap_probability = np.percentile(np.abs(gaps), [50, 75, 90, 95])
```

**User Benefit**: "Know if holding over the weekend is worth the risk"

---

### TILE 10: Theta Decay Curves â°
**Category**: Options Greeks  
**Formula Type**: Black-Scholes Theta  
**ML Required**: âŒ No

**What It Shows**:
- Theta decay acceleration by DTE
- Optimal entry/exit DTEs
- "Theta Cliff" warning zones

**Visualization**:
```
Theta Decay (% per day)
â”‚
â”‚     â—„â”€â”€ Acceleration Zone
â”‚        â•±
â”‚       â•±
â”‚      â•±
â”‚â”€â”€â”€â”€â”€â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
â”‚               â†‘
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ DTE
      7   5   3   1
```

---

### TILE 11: Monte Carlo Cones ğŸ”®
**Category**: Price Projection  
**Formula Type**: Monte Carlo Simulation  
**ML Required**: âŒ No

**What It Shows**:
- Price cones at 1Ïƒ, 2Ïƒ, 3Ïƒ levels
- 5-day forward projection
- Probability at each price level

**Display**:
```
                    â•± 3Ïƒ (99.7%)
                   â•±  2Ïƒ (95%)
                  â•±   1Ïƒ (68%)
    SPOT â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â•²
                  â•²   1Ïƒ
                   â•²  2Ïƒ
                    â•² 3Ïƒ
    â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â†’
    D+0  D+1  D+2  D+3  D+4
```

---

### TILE 12: Barrier Breach Probability ğŸš§
**Category**: Options Pricing  
**Formula Type**: Black-Scholes Barrier  
**ML Required**: âŒ No

**What It Shows**:
- Probability of touching key strike levels
- Dynamic barrier visualization
- Risk-reward for barrier options

**Barriers Calculated**:
- ATM Â± 1%
- ATM Â± 2%
- ATM Â± 3%

---

### TILE 13: Streak Reversal ğŸ”„
**Category**: Statistical Pattern  
**Formula Type**: Empirical + Bayesian  
**ML Required**: âœ… Yes (Random Forest)

**What It Shows**:
- Current streak (consecutive up/down days)
- Historical reversal probability after similar streaks
- ML-enhanced reversal confidence

**Formula**:
```python
# After 3 consecutive up days, probability of down day
streak_reversal_prob = model.predict_proba(streak_features)
```

---

### TILE 14: Pain Zone ğŸ¯
**Category**: Market Structure  
**Formula Type**: Max Pain + Volume Profile  
**ML Required**: âŒ No

**What It Shows**:
- Estimated max pain zone (volume-weighted center)
- Price attraction levels
- Magnetic price targets

**Calculation**:
```python
# Volume-weighted average price zones
pain_zone = np.average(price_levels, weights=volume_at_levels)
attraction_strength = volume_concentration_ratio
```

---

### TILE 15: Range Quartiles ğŸ“Š
**Category**: Statistical Range  
**Formula Type**: Quantile Regression  
**ML Required**: âœ… Yes (Quantile Regression)

**What It Shows**:
- Expected range (Q25 to Q75)
- Extreme range (Q10 to Q90)
- Current price position within range

**Visualization**:
```
Q10 â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€ Q90
         â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”‚
         â”‚ Q25 â”‚ SPOT  â”‚Q75â”‚
         â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### TILE 16: Momentum Pulse ğŸ’“
**Category**: Technical  
**Formula Type**: RSI + MACD + Momentum Composite  
**ML Required**: âœ… Yes (Gradient Boosting)

**What It Shows**:
- Composite momentum score (0-100)
- Overbought/Oversold zones
- Momentum divergence detection

**Components**:
- RSI (14-day)
- MACD Signal Line Cross
- Rate of Change (20-day)
- Stochastic K/D

---

### TILE 17: GEX Cluster ğŸ”¥
**Category**: Dealer Positioning  
**Formula Type**: Volume-Proxy GEX  
**ML Required**: âŒ No (Volume Proxy)

**What It Shows**:
- Estimated dealer gamma exposure
- Expected volatility dampening/amplification
- Key gamma flip levels

**Interpretation**:
| GEX | Effect | Price Behavior |
|-----|--------|----------------|
| +High | Dampening | Mean-reverting |
| -High | Amplifying | Trend extension |
| Near Zero | Neutral | Normal volatility |

---

### TILE 18: Event Radar ğŸ“¡
**Category**: Calendar  
**Formula Type**: Empirical Event Impact  
**ML Required**: âŒ No

**What It Shows**:
- Upcoming market events (RBI, Expiry, etc.)
- Historical impact of similar events
- Volatility expansion expectation

**Events Tracked**:
- Monthly expiry
- Weekly expiry
- RBI policy days
- US Fed announcements
- Budget day (annual)

---

### TILE 19: Trade Traffic Light ğŸš¦ {NEW}
**Category**: Beginner Logic  
**Formula Type**: Multi-Factor Confluence  
**ML Required**: âœ… Yes (Uses Regime + Momentum Outputs)

**What It Shows**:
- **GO (Green)**: Market is safe for new entries
- **WAIT (Yellow)**: Mixed signals, reduce size
- **STOP (Red)**: Dangerous conditions (Choppy/High Vol)

**Logic**:
- **Green**: Regime=Trending AND VIX<20 AND Momentum>60
- **Red**: Regime=Chaotic OR VIX>24
- **Yellow**: Everything else

**User Benefit**: "Simple Yes/No answer for 'Should I trade today?'"

---

### TILE 20: FOMO Meter ğŸ˜± {NEW}
**Category**: Psychology / Risk  
**Formula Type**: Mean Reversion Logic  
**ML Required**: âŒ No

**What It Shows**:
- Gauge measuring how "over-extended" the price is
- Prevents buying at the top or selling at the bottom

**Logic**:
- **EXTREME FOMO (Don't Buy)**: RSI > 75 OR Price > Upper BB (2Ïƒ)
- **HIGH RISK**: RSI 65-75
- **NEUTRAL**: RSI 35-65
- **EXTREME PANIC (Don't Sell)**: RSI < 25 OR Price < Lower BB (2Ïƒ)

**User Benefit**: "Saves you from bad entries driven by emotion"

## ğŸ¨ Design Theme: TRON LEGACY Ã— JARVIS

### Color Palette

```css
:root {
  /* Primary Colors - TRON Legacy Cyan */
  --tron-cyan: #00FFFF;
  --tron-cyan-glow: rgba(0, 255, 255, 0.3);
  --tron-orange: #FF6600;
  --tron-orange-glow: rgba(255, 102, 0, 0.3);
  
  /* Background - Deep Space */
  --bg-primary: #0A0A0F;
  --bg-secondary: #12121A;
  --bg-card: #1A1A25;
  --bg-card-hover: #222230;
  
  /* JARVIS-style Accent */
  --jarvis-blue: #4A90D9;
  --jarvis-gold: #FFD700;
  
  /* Grid Lines */
  --grid-line: rgba(0, 255, 255, 0.1);
  --grid-highlight: rgba(0, 255, 255, 0.3);
  
  /* Text */
  --text-primary: #FFFFFF;
  --text-secondary: #8892B0;
  --text-muted: #4A5568;
  
  /* Signals */
  --signal-bullish: #00FF88;
  --signal-bearish: #FF4444;
  --signal-neutral: #888888;
}
```

### Background Animations

```css
/* Animated Grid Background - TRON Style */
.tron-grid-background {
  background-image: 
    linear-gradient(rgba(0, 255, 255, 0.05) 1px, transparent 1px),
    linear-gradient(90deg, rgba(0, 255, 255, 0.05) 1px, transparent 1px);
  background-size: 50px 50px;
  animation: grid-pulse 4s ease-in-out infinite;
}

@keyframes grid-pulse {
  0%, 100% { opacity: 0.3; }
  50% { opacity: 0.6; }
}

/* Floating Particles - JARVIS Hologram */
.particle-field::before {
  content: '';
  position: absolute;
  width: 200%;
  height: 200%;
  background: radial-gradient(
    circle at 50% 50%,
    rgba(0, 255, 255, 0.1) 0%,
    transparent 50%
  );
  animation: particle-drift 20s linear infinite;
}

@keyframes particle-drift {
  0% { transform: translate(-50%, -50%) rotate(0deg); }
  100% { transform: translate(-50%, -50%) rotate(360deg); }
}

/* Scan Line Effect */
.scan-line::after {
  content: '';
  position: absolute;
  width: 100%;
  height: 2px;
  background: linear-gradient(
    90deg,
    transparent,
    var(--tron-cyan),
    transparent
  );
  animation: scan 3s linear infinite;
}

@keyframes scan {
  0% { top: -2px; opacity: 0; }
  50% { opacity: 1; }
  100% { top: 100%; opacity: 0; }
}
```

### Tile Styling

```css
/* Glass Morphism Tiles */
.omega-tile {
  background: rgba(26, 26, 37, 0.8);
  backdrop-filter: blur(10px);
  border: 1px solid rgba(0, 255, 255, 0.2);
  border-radius: 12px;
  box-shadow: 
    0 4px 20px rgba(0, 0, 0, 0.5),
    inset 0 1px 0 rgba(255, 255, 255, 0.1);
  transition: all 0.3s ease;
}

.omega-tile:hover {
  border-color: var(--tron-cyan);
  box-shadow: 
    0 8px 40px rgba(0, 255, 255, 0.2),
    0 0 20px rgba(0, 255, 255, 0.1);
  transform: translateY(-2px);
}

/* Neon Glow Effect on Hover */
.omega-tile::before {
  content: '';
  position: absolute;
  inset: -2px;
  border-radius: 14px;
  background: linear-gradient(
    45deg,
    var(--tron-cyan),
    var(--tron-orange),
    var(--tron-cyan)
  );
  z-index: -1;
  opacity: 0;
  transition: opacity 0.3s ease;
}

.omega-tile:hover::before {
  opacity: 0.5;
  animation: border-glow 2s linear infinite;
}

@keyframes border-glow {
  0% { background-position: 0% 50%; }
  50% { background-position: 100% 50%; }
  100% { background-position: 0% 50%; }
}
```

### Dark/Light Mode

```css
/* Dark Mode (Default) */
[data-theme="dark"] {
  --bg-primary: #0A0A0F;
  --text-primary: #FFFFFF;
  --tron-cyan: #00FFFF;
}

/* Light Mode - Frosted Glass */
[data-theme="light"] {
  --bg-primary: #F0F4F8;
  --bg-secondary: #FFFFFF;
  --bg-card: rgba(255, 255, 255, 0.9);
  --text-primary: #1A202C;
  --text-secondary: #4A5568;
  --tron-cyan: #0077B6;
  --grid-line: rgba(0, 119, 182, 0.1);
}

/* Light mode keeps the futuristic feel with blue accents */
[data-theme="light"] .omega-tile {
  background: rgba(255, 255, 255, 0.8);
  border-color: rgba(0, 119, 182, 0.2);
}
```

---

## ğŸ› ï¸ Technology Stack

### Frontend

| Technology | Version | Purpose |
|------------|---------|---------|
| **Vite** | 5.4.x | Build tool & dev server |
| **React** | 18.3.x | UI framework |
| **TypeScript** | 5.3.x | Type safety |
| **Tailwind CSS** | 3.4.x | Utility styling |
| **Framer Motion** | 11.x | Animations |
| **Recharts** | 2.15.x | Charting library |
| **React Query** | 5.x | Data fetching |
| **Three.js** | 0.165.x | 3D probability surface (optional) |

### Backend (Python)

| Technology | Version | Purpose |
|------------|---------|---------|
| **Python** | 3.12+ | Runtime |
| **yfinance** | 0.2.x | Data source (SOLE source of truth) |
| **pandas** | 2.2.x | Data manipulation |
| **numpy** | 1.26.x | Numerical computing |
| **scipy** | 1.13.x | Statistical functions |
| **scikit-learn** | 1.4.x | ML models |
| **hmmlearn** | 0.3.x | Hidden Markov Models |
| **joblib** | 1.4.x | Model persistence |

### Infrastructure (Zero Cost)

| Component | Tier | Usage |
|-----------|------|-------|
| **GitHub Actions** | Free | CI/CD, scheduled inference |
| **Cloudflare Pages** | Free | Frontend hosting |
| **GitHub Repo** | Free | Model storage |

---

## ğŸ“ Project Structure

```
omega-vault/
â”œâ”€â”€ client/                          # React Frontend (Vite)
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â””â”€â”€ omega_vault.json    # Generated predictions
â”‚   â”‚   â”œâ”€â”€ favicon.svg             # Cyan Î© icon
â”‚   â”‚   â””â”€â”€ og-image.png            # Social preview
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ tiles/              # 16 tile components
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ProbabilitySurface.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ RegimeBeacon.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ KellyOptimal.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ VaRGauge.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ HurstCompass.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ VIXTermContour.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ FridayFear.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ThetaDecay.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MonteCarloCones.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ BarrierBreach.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ StreakReversal.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ PainZone.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ RangeQuartiles.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MomentumPulse.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ GEXCluster.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ EventRadar.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ layout/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Header.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ TileGrid.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ effects/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ TronGrid.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ScanLine.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ParticleField.tsx
â”‚   â”‚   â”‚   â””â”€â”€ VerdictHero.tsx
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â””â”€â”€ useOmegaData.ts
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”œâ”€â”€ types.ts
â”‚   â”‚   â”‚   â””â”€â”€ formatters.ts
â”‚   â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â”‚   â””â”€â”€ globals.css
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ engine/                          # Python Backend
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ data_fetcher.py         # yfinance data ingestion
â”‚   â”‚   â”œâ”€â”€ feature_engineer.py     # Technical indicators
â”‚   â”‚   â”œâ”€â”€ probability_models.py   # Monte Carlo, BSM
â”‚   â”‚   â”œâ”€â”€ regime_detector.py      # HMM training
â”‚   â”‚   â”œâ”€â”€ risk_calculator.py      # VaR, CVaR, Kelly
â”‚   â”‚   â”œâ”€â”€ ml_models.py            # RF, XGBoost training
â”‚   â”‚   â”œâ”€â”€ infer.py                # Daily inference
â”‚   â”‚   â””â”€â”€ run_all.py              # Master script
â”‚   â”œâ”€â”€ models/                      # Trained model files
â”‚   â”‚   â”œâ”€â”€ hmm_regime.pkl
â”‚   â”‚   â”œâ”€â”€ rf_momentum.pkl
â”‚   â”‚   â”œâ”€â”€ qr_range.pkl
â”‚   â”‚   â””â”€â”€ xgb_reversal.pkl
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ NSEI_daily.csv
â”‚   â”‚   â”œâ”€â”€ NSEBANK_daily.csv
â”‚   â”‚   â””â”€â”€ INDIAVIX_daily.csv
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ weekly_training.yml     # Saturday model retraining
â”‚       â””â”€â”€ daily_inference.yml     # M-F 30-min inference
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ SEBI_COMPLIANCE.md
â”‚
â””â”€â”€ README.md
```

---

## ğŸš€ Training & Inference Pipeline

### Weekly Training (Saturdays)

```mermaid
graph LR
    A[yfinance.download] --> B[NIFTY + BANKNIFTY + VIX<br/>2005-Present]
    B --> C[Feature Engineering<br/>50+ features]
    C --> D{Train Models}
    D --> E[HMM Regime]
    D --> F[RF Momentum]
    D --> G[XGBoost Reversal]
    D --> H[Quantile Range]
    E --> I[Save to models/]
    F --> I
    G --> I
    H --> I
    I --> J[Commit to GitHub]
```

**Training Time**: ~10-15 minutes  
**Model Size**: ~15 MB total  
**Data Period**: 2005 to present (~20 years)

### Daily Inference (Every 30 min, Market Hours)

```mermaid
graph LR
    A[Load Trained Models] --> B[Fetch Recent Data<br/>yfinance 1y + live]
    B --> C[Build Features]
    C --> D[Run Inference]
    D --> E[Monte Carlo<br/>10,000 paths]
    D --> F[HMM Predict<br/>Current regime]
    D --> G[Kelly Calculate<br/>Position size]
    D --> H[VaR Estimate<br/>Risk gauge]
    E --> I[omega_vault.json]
    F --> I
    G --> I
    H --> I
    I --> J[Commit & Deploy]
```

**Inference Time**: ~30 seconds  
**Update Frequency**: Every 30 min (9:15 AM - 3:30 PM IST)

---

## ğŸ“ˆ User Benefit Summary

| Tile | User Benefit | Confidence Boost |
|------|--------------|------------------|
| **Probability Surface** | Know WHERE price will likely go | "I see the odds, not guesses" |
| **Regime Beacon** | Know WHEN your strategy works | "I trade WITH the market flow" |
| **Kelly Optimal** | Know HOW MUCH to risk | "My sizing is mathematically optimal" |
| **VaR Gauge** | Know your WORST CASE | "I sleep better knowing my max loss" |
| **Hurst Compass** | Know IF trend will continue | "I know when to ride or fade" |
| **VIX Term Contour** | Know WHEN to sell premium | "I collect premium at the right time" |
| **Friday Fear** | Know WEEKEND gap risk | "I don't hold blindly over weekends" |
| **Theta Decay** | Know WHEN options bleed | "I time my entries perfectly" |
| **Monte Carlo Cones** | See PROBABILITY RANGES | "I see all possible outcomes" |
| **Barrier Breach** | Know STRIKE touch odds | "I price my stop losses correctly" |
| **Streak Reversal** | Know WHEN to bet against streak | "I catch reversals early" |
| **Pain Zone** | Know WHERE price gets attracted | "I trade to where price wants to go" |
| **Range Quartiles** | Know EXPECTED movement | "I set realistic targets" |
| **Momentum Pulse** | Know CONVICTION strength | "I trade only strong setups" |
| **GEX Cluster** | Know DEALER positioning | "I trade with smart money" |
| **Event Radar** | Know WHAT's coming | "I'm never surprised by events" |

---

## ğŸ›¡ï¸ SEBI Compliance

> **DISCLAIMER**: This dashboard provides **statistical analysis and probability calculations** for **educational purposes only**. It does **NOT** provide:
> - Investment advice
> - Buy/Sell recommendations
> - Guaranteed returns
> - Stock tips

### Compliance Measures

1. **No Recommendations**: All outputs are probabilities, not "BUY" or "SELL" signals
2. **Risk Warnings**: Every tile shows associated risks
3. **Past Performance Disclaimer**: Historical accuracy is displayed but not guaranteed
4. **Educational Labeling**: Clear "For Educational Use Only" badges
5. **No SEBI Registration Required**: As per SEBI Investment Adviser Regulations 2013, statistical tools don't require registration

---

## ğŸ’° Revenue Model

### Ad-Supported (Zero User Cost)

| Ad Placement | Size | Network |
|--------------|------|---------|
| Header banner | 728Ã—90 | Adsterra |
| Sidebar | 300Ã—250 | Adsterra |
| Between tiles | Native | Adsterra |
| Mobile bottom | 320Ã—50 | Adsterra |

### Traffic Potential

| Metric | Estimate |
|--------|----------|
| **Target Market** | 50M+ Indian F&O traders |
| **TAM Capture** | 0.1% = 50,000 daily users |
| **Page Views/User** | 5 (multiple tiles) |
| **Daily Page Views** | 250,000 |
| **RPM (India)** | $1-3 |
| **Monthly Revenue** | $7,500 - $22,500 |

---

## ğŸŒŠ High Traffic Potential

### Why Users Will Flock

1. **Unique Value Prop**: No other free tool offers probability-first options analytics
2. **Premium Feel**: Institutional-grade formulas, futuristic UI
3. **Trust Building**: Transparent formulas, no hidden "secret sauce"
4. **Community Growth**: Share-worthy screenshots, social buzz potential
5. **SEO Advantage**: "NIFTY probability calculator", "BANKNIFTY VaR" keywords
6. **Mobile PWA**: Installable on phones for quick checks

### Competition Gap

| Existing Tools | Our Advantage |
|----------------|---------------|
| TradingView | No probability models, charting-only |
| Sensibull | Options-focused but premium paywall |
| Opstra | Complex, not beginner-friendly |
| Generic screeners | Stock-focused, not F&O |

**Omega Vault fills the gap**: **Free + Probability-focused + Options-specific + Premium UI**

---

## âš¡ Quick Start

### Local Development

```bash
# 1. Clone repository
git clone https://github.com/yourusername/omega-vault.git
cd omega-vault

# 2. Install frontend dependencies
cd client
npm install

# 3. Install Python dependencies
cd ../engine
pip install -r requirements.txt

# 4. Run data pipeline
python scripts/run_all.py

# 5. Start frontend
cd ../client
npm run dev

# Open http://localhost:5173
```

### Production Deployment

```bash
# Auto-deploys via GitHub Actions
git push origin main
# â†’ weekly_training.yml runs on Saturdays
# â†’ daily_inference.yml runs every 30 min M-F
# â†’ Cloudflare Pages auto-deploys on commit
```

---

## ğŸ“ Summary

**Tradyxa Omega Vault** is a **flagship, enterprise-level** probabilistic intelligence dashboard for **NIFTY and BANKNIFTY options traders**. It combines:

- **Goldman Sachs-style probability models**
- **BlackRock-style risk management (VaR, Kelly)**
- **DE Shaw-style regime detection (HMM)**
- **Citadel-style Greeks estimation**

All powered by **yfinance as the sole data source**, with **zero infrastructure cost**, and delivered through a **stunning TRON Legacy Ã— JARVIS themed UI**.

**Sleep better. Trade smarter. Trust the probabilities.**

---

*Version 1.0.0 | Last Updated: December 2025 | For Educational Use Only*
